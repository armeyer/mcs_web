\chapter{Generating Functions}\label{generating_function_chap}

\idx{Generating Functions} are one of the most surprising and useful
inventions in Discrete Math.  Roughly speaking, generating functions
transform problems about \emph{sequences} into problems about
\emph{functions}.  This is great because we've got piles of
mathematical machinery for manipulating functions.  Thanks to
generating functions, we can then apply all that machinery to problems
about sequences.  In this way, we can use generating functions to
solve all sorts of counting problems.  They can also be used to find
closed-form expressions for sums and to solve recurrences.  In fact,
many of the problems we addressed in
Chapters~\hbox{\ref{chap:asymptotics}--\ref{counting_chap}} can be
formulated and solved using generating functions.

\section{Definitions and Examples}

The \term{ordinary generating function} for the sequence\footnote{In
  this chapter, we'll put sequences in angle brackets to more clearly
  distinguish them from the many other mathematical expressions
  floating around.} $\ang{g_0, g_1, g_2, g_3 \dots}$ is the power
series:
\[
G(x) = g_0 + g_1 x + g_2 x^2 + g_3 x^3 + \cdots.
\]
There are a few other kinds of generating functions in common use, but
ordinary generating functions are enough to illustrate the power of
the idea, so we'll stick to them and from now on, \emph{generating
  function} will mean the ordinary kind.

A generating function is a ``formal'' power series in the sense that we
usually regard $x$ as a placeholder rather than a number.  Only in rare
cases will we actually evaluate a generating function by letting $x$ take
a real number value, so we generally ignore the issue of \idx{convergence}.

Throughout this chapter, we'll indicate the correspondence between a
sequence and its generating function with a double-sided arrow as
follows:
%
\[
\ang{g_0, g_1, g_2, g_3, \dots}
    \corresp g_0 + g_1 x + g_2 x^2 + g_3 x^3 + \cdots.
\]
%
For example, here are some sequences and their generating functions:
%
\begin{align*}
\ang{0, 0, 0, 0, \dots}
    & \corresp 0 + 0 x + 0 x^2 + 0 x^3 + \cdots = 0 \\
\ang{1, 0, 0, 0, \dots}
    & \corresp 1 + 0 x + 0 x^2 + 0 x^3 + \cdots = 1 \\
\ang{3, 2, 1, 0, \dots}
    & \corresp 3 + 2 x + 1 x^2 + 0 x^3 + \cdots = 3 + 2 x + x^2
\end{align*}
%
The pattern here is simple: the $i$th term in the sequence (indexing
from 0) is the coefficient of~$x^i$ in the generating function.

Recall that the sum of an infinite \idx{geometric series} is:
%
\[
    1 + z + z^2 + z^3 + \cdots = \frac{1}{1 - z}.
\]
%
This equation does not hold when $\abs{z} \geq 1$, but as remarked, we
won't worry about convergence issues for now.  This formula gives
\idx{closed form} generating functions for a whole range of sequences.
For example:
%
\begin{alignat*}{3}
\ang{1, 1, 1, 1, \dots}
    & \corresp 1 + x + x^2 + x^3 + x^4 + \cdots
    & {}= \dfrac{1}{1-x} \\
\\
\ang{1, -1, 1, -1, \dots}
    & \corresp 1 - x + x^2 - x^3 + x^4 - \cdots
    &  {}= \dfrac{1}{1+x} \\
\\
\ang{1, a, a^2, a^3, \dots}
    & \corresp 1 + a x + a^2 x^2 + a^3 x^3 + \cdots
    &  {}= \dfrac{1}{1-ax} \\
\\
\ang{1, 0, 1, 0, 1, 0, \dots}
    & \corresp 1 + x^2 + x^4 + x^6 + x^8 + \cdots
    & {}= \dfrac{1}{1 - x^2}
\end{alignat*}

\section{Operations on Generating Functions}

The magic of generating functions is that we can carry out all sorts
of manipulations on sequences by performing mathematical operations on
their associated generating functions.  Let's experiment with various
operations and characterize their effects in terms of sequences.

\subsection{Scaling}

Multiplying a generating function by a constant scales every term in
the associated sequence by the same constant.  For example, we noted
above that:
%
\[
\ang{1, 0, 1, 0, 1, 0, \dots}
    \corresp 1 + x^2 + x^4 + x^6 + \cdots = \frac{1}{1 - x^2}.
\]
%
Multiplying the generating function by 2 gives
%
\[
    \frac{2}{1 - x^2} = 2 + 2 x^2 + 2 x^4 + 2 x^6 + \cdots
\]
%
which generates the sequence:
%
\[
    \ang{2, 0, 2, 0, 2, 0, \dots}.
\]

\begin{rul}[\idx{Scaling Rule}]
\label{rule:scaling}
If
\[\ang{f_0, f_1, f_2, \dots} \corresp F(x),\]
then
%
\[
\ang{c f_0,\ c f_1,\ c f_2,\ \dots} \corresp c \cdot F(x).
\]
\end{rul}

The idea behind this rule is that:
\begin{align*}
\ang{c f_0, c f_1, c f_2, \dots}
    & \corresp c f_0 + c f_1 x + c f_2 x^2 + \cdots \\
    & = c \cdot (f_0 + f_1 x + f_2 x^2 + \cdots) \\
    & = c F(x).
\end{align*}

\subsection{Addition}

Adding generating functions corresponds to adding the two sequences
term by term.  For example, adding two of our earlier examples gives:
%
\[
\begin{array}{c@{}c@{}c@{\,}c@{\,}c@{\,}c@{\,}c@{\,}c@{\,}c@{\,}c@{\;}c@{\;}l}
  & \langle & 1, & 1, & 1, & 1, & 1, & 1, & \dots & \rangle &
    \corresp & \dfrac{1}{1-x} \\[8pt]
{}+{} & \langle & 1, & -1, & 1, & -1, & 1, & -1, & \dots & \rangle &
    \corresp & \dfrac{1}{1+x} \\[8pt]
\hline
\noalign{\vskip3pt}
& \langle & 2, & 0, & 2, & 0, & 2, & 0, & \dots & \rangle &
    \corresp & \dfrac{1}{1-x} + \dfrac{1}{1+x}
\end{array}
\]
%
We've now derived two different expressions that both generate the
sequence $\ang{2, 0, 2, 0, \dots}$.  They are, of course, equal:
%
\[
\frac{1}{1-x} + \frac{1}{1+x}
    = \frac{(1 + x) + (1 - x)}{(1-x)(1+x)} = \frac{2}{1-x^2}.
\]

\begin{rul}[\index{Addition Rule (for generating functions)}Addition Rule]
\label{rule:addition}
If
%
\begin{align*}
\ang{f_0, f_1, f_2, \dots} & \corresp F(x) \qquad \text{and} \\
\ang{g_0, g_1, g_2, \dots} & \corresp G(x),
\end{align*}
%
then
%
\[
\ang{f_0 + g_0,\ f_1 + g_1,\ f_2 + g_2,\ \dots}
    \corresp F(x) + G(x).
\]
\end{rul}

The idea behind this rule is that:
\begin{align*}
\ang{f_0 + g_0,\ f_1 + g_1,\ f_2 + g_2,\ \dots}
    & \corresp \sum_{n=0}^\infty (f_n + g_n) x^n \\
    & = \paren{\sum_{n=0}^\infty f_n x^n} +
        \paren{\sum_{n=0}^\infty g_n x^n} \\
    & = F(x) + G(x).
\end{align*}

\subsection{Right Shifting}

Let's start over again with a simple sequence and its generating
function:
%
\[
    \ang{1, 1, 1, 1, \dots} \corresp \frac{1}{1-x}.
\]
%
Now let's \term{right-shift} the sequence by adding $k$ leading
zeros:
%
\begin{align*}
\langle\overbrace{0, 0, \dots, 0}^{\text{$k$ zeroes}}, 1, 1, 1, \dots\rangle
        & \corresp x^k + x^{k+1} + x^{k+2} + x^{k+3} + \cdots \\
        & = x^k \cdot (1  + x + x^2 + x^3 + \cdots) \\
        & = \frac{x^k}{1-x}.
\end{align*}
%
Evidently, adding $k$ leading zeros to the sequence corresponds to
multiplying the generating function by $x^k$.  This holds true in
general.

\begin{rul}[\idx{Right-Shift Rule}]
\label{rule:shift}
If $\ang{f_0, f_1, f_2, \dots} \corresp F(x)$, then:
%
\[
\langle \overbrace{0, 0, \dots, 0}^{\text{$k$ zeroes}}, f_0, f_1, f_2, \dots\rangle \corresp x^k \cdot F(x).
\]
\end{rul}

The idea behind this rule is that:
\begin{align*}
\langle\overbrace{0, 0, \dots, 0}^{\text{$k$ zeroes}}, f_0, f_1, f_2, \dots\rangle
    & \corresp f_0 x^k + f_1 x^{k+1} + f_2 x^{k+2} + \cdots \\
    & = x^k \cdot (f_0 + f_1 x + f_2 x^2 + f_3 x^3 + \cdots) \\
    & = x^k \cdot F(x).
\end{align*}

\subsection{Differentiation}

What happens if we take the \term{derivative} of a generating
function?  As an example, let's differentiate the now-familiar
generating function for an infinite sequence of~1's:
%
\begin{alignat}{2}
&\quad&
    1 + x + x^2 + x^3 + x^4 + \cdots
        & {}= \frac{1}{1-x} \notag\\
{}\QIMPLIES{}
    &&\frac{d}{dx} \ (1 + x + x^2 + x^3 + x^4 + \cdots)
        & = \frac{d}{dx} \paren{\frac{1}{1-x}} \notag\\
{}\QIMPLIES{}&&
    1 + 2x + 3x^2 + 4x^3 + \cdots & = \frac{1}{(1-x)^2} \notag\\
{}\QIMPLIES{}&&
    \ang{1, 2, 3, 4, \dots}  & \corresp \frac{1}{(1-x)^2}.\label{sumixi-1}
\end{alignat}
%
We found a generating function for the sequence $\ang{1, 2, 3, 4,
\dots}$ of positive integers!

In general, differentiating a generating function has two effects on
the corresponding sequence: each term is multiplied by its index and
the entire sequence is shifted left one place.

\begin{rul}[\idx{Derivative Rule}]
\label{rule:derivative}
If
\[
\ang{f_0, f_1, f_2, f_3, \dots} \corresp F(x),
\]
then
%
\[
\ang{f_1, 2f_2, 3f_3, \dots} \corresp F'(x).
\]
\end{rul}

The idea behind this rule is that:
\begin{align*}
\ang{f_1, 2f_2, 3f_3, \dots}
    & \corresp f_1 + 2 f_2 x + 3 f_3 x^2 + \cdots \\
    & = \frac{d}{dx} \ (f_0 + f_1 x + f_2 x^2 + f_3 x^3 + \cdots) \\
    & = \frac{d}{dx} \ F(x).
\end{align*}

The Derivative Rule is very useful.  In fact, there is frequent,
independent need for each of differentiation's two effects,
multiplying terms by their index and left-shifting one place.
Typically, we want just one effect and must somehow cancel out the
other.  For example, let's try to find the generating function for the
sequence of squares, $\ang{0, 1, 4, 9, 16, \dots}$.  If we could
start with the sequence $\ang{1, 1, 1, 1, \dots}$ and multiply each term by
its index two times, then we'd have the desired result:
%
\[
\ang{0 \cdot 0,\ 1 \cdot 1,\ 2 \cdot 2,\ 3 \cdot 3,\ \dots}
=
\ang{0, 1, 4, 9, \dots}.
\]
%
A challenge is that differentiation not only multiplies each term by
its index, but also shifts the whole sequence left one place.
However, the Right-Shift Rule~\ref{rule:shift} tells how to cancel out
this unwanted left-shift: multiply the generating function by~$x$.

Our procedure, therefore, is to begin with the generating function for
$\ang{1, 1, 1, 1, \dots}$, differentiate, multiply by~$x$, and then
differentiate and multiply by~$x$ once more.  Then
%
\begingroup
\openup3pt
\begin{alignat*}{3}
&\quad&
\ang{1, 1, 1, 1, \dots}  & \corresp \frac{1}{1-x}
&\enskip& \\
\text{Derivative Rule:} &&
\ang{1, 2, 3, 4, \dots}  & \corresp \frac{d}{dx} \ \frac{1}{1-x}
                                          &{}= \frac{1}{(1-x)^2}\\
\text{Right-shift Rule:} &&
\ang{0, 1, 2, 3, \dots}  & \corresp x \cdot \frac{1}{(1-x)^2}
                                          &{}= \frac{x}{(1-x)^2}\\
\text{Derivative Rule:} &&
\ang{1, 4, 9, 16, \dots} & \corresp \frac{d}{dx} \ \frac{x}{(1-x)^2}
                                          &{}= \frac{1+x}{(1-x)^3} \\
\text{Right-shift Rule:} &&
\ang{0, 1, 4, 9, \dots}  & \corresp x \cdot \frac{1+x}{(1-x)^3}
                                          &{}= \frac{x(1+x)}{(1-x)^3}
\end{alignat*}
\endgroup
%
Thus, the generating function for squares is:
%
\begin{equation}\label{squares_gen_func}
    \frac{x(1+x)}{(1-x)^3}.
\end{equation}

\subsection{Products}

\begin{rul}[\index{Product Rule (for generating functions)} Product Rule]
\label{rule:product}
If
%
\[
\ang{a_0, a_1, a_2, \dots} \corresp A(x),\quad \text{and}\quad
\ang{b_0, b_1, b_2, \dots} \corresp B(x),
\]
%
then
%
\[
\ang{c_0,\ c_1 ,\ c_2,\ \dots} \corresp A(x) \cdot B(x),
\]
\end{rul}
where
\[
c_n \eqdef a_0 b_n + a_1 b_{n-1} + a_2 b_{n-2} + \cdots + a_n b_0.
\]

To understand this rule, let
\[
C(x) \eqdef A(x) \cdot B(x) = \sum_{n=0}^{\infty} c_n x^n.
\]

We can evaluate the product $A(x) \cdot B(x)$ by using a table to identify
all the cross-terms from the product of the sums:
%
\[
\begin{array}{c|@{\quad}c@{\qquad}c@{\qquad}c@{\qquad}c@{\qquad}c}
        & b_0 x^0 & b_1 x^1 & b_2 x^2 & b_3 x^3 & \dots \\
\hline
\\
a_0 x^0 & a_0 b_0 x^0 & a_0 b_1 x^1 & a_0 b_2 x^2 & a_0 b_3 x^3 & \dots \\
\\
a_1 x^1 & a_1 b_0 x^1 & a_1 b_1 x^2 & a_1 b_2 x^3 & \dots \\
\\
a_2 x^2 & a_2 b_0 x^2 & a_2 b_1 x^3 & \dots \\
\\
a_3 x^3 & a_3 b_0 x^3 & \dots \\
\\
\vdots & \dots\\
\end{array}
\]
%
Notice that all terms involving the same power of~$x$ lie on a
diagonal.  Collecting these terms together, we find that the
coefficient of $x^n$ in the product is the sum of all the terms on the
$(n+1)$st diagonal, namely,
\begin{equation}\label{conv}
a_0 b_n + a_1 b_{n-1} + a_2 b_{n-2} + \cdots + a_n b_0.
\end{equation}
This expression~\eqref{conv} may be familiar from a signal processing
course; the sequence $\ang{c_0, c_1, c_2, \dots}$ is called the
\term{convolution} of sequences $\ang{a_0, a_1, a_2, \dots}$ and
$\ang{b_0, b_1, b_2, \dots}$.

\section{Evaluating Sums}

The product rule looks complicated.  But it is surprisingly useful.
For example, suppose that we set
\begin{equation*}
    B(x) = \frac{1}{1 - x}.
\end{equation*}
Then $b_i = 1$ for $i \ge 0$ and the $n$th coefficient of $A(x) B(x)$
is
\begin{equation*}
a_0 \cdot 1 + a_1 \cdot 1 + a_2 \cdot 1 + \dots + a_n \cdot 1
    = \sum_{i = 0}^n a_i.
\end{equation*}
In other words, given any sequence~$\ang{a_0, a_1, a_2, \dots}$, we can
compute
\begin{equation*}
    s_n = \sum_{i = 0}^n a_i
\end{equation*}
for all~$n$ by simply multiplying the sequence's generating function
by~$1/(1 - x)$.  This is the Summation Rule.

\begin{rul}[\index{Summation Rule (for generating functions)}%
    Summation Rule]
If
\begin{equation*}
    \ang{a_0, a_1, a_2, \dots} \corresp A(x),
\end{equation*}
then
\begin{equation*}
    \ang{s_0, s_1, s_2, \dots} \corresp \frac{A(x)}{1 - x}
\end{equation*}
where
\begin{equation*}
    s_n = \sum_{i = 0}^n a_i\quad\text{for $n \ge 0$}.
\end{equation*}
\end{rul}

The Summation Rule sounds powerful, and it is!  We know from
Chapter~\ref{chap:asymptotics} that computing sums is often not easy.
But multiplying by~$1/(1 - x)$ is about as easy as it gets.

For example, suppose that we want to compute the sum of the first
$n$~squares
\begin{equation*}
    s_n = \sum_{i = 0}^n i^2
\end{equation*}
and we forgot the method in Chapter~\ref{chap:asymptotics}.  All we
need to do is compute the generating function for~$\sequence{0, 1, 4,
  9, \dots}$ and multiply by~$1/(1 - x)$.  We already computed the
generating function for ~$\sequence{0, 1, 4, 9, \dots}$ in
Equation~\ref{squares_gen_func}---it is
\begin{equation*}
    \frac{x (1 + x)}{(1 - x)^3}.
\end{equation*}
Hence, the generating function for~$\sequence{s_0, s_1, s_2, \dots}$
is
\begin{equation*}
    \frac{x (1 + x)}{(1 - x)^4}.
\end{equation*}
This means that $\sum_{i = 0}^n i^2$ is the coefficient of~$x^n$ in~$x
(1 + x)/(1 - x)^4$.

That was pretty easy, but there is one problem---we have no idea how
to determine the coefficient of~$x^n$ in~$x(1 + x)/(1 - x)^4$!  And
without that, this whole endeavor (while magical) would be useless.
Fortunately, there is a straightforward way to produce the sequence of
coefficients from a generating function.

\section{Extracting Coefficients}

\subsection{Taylor Series}

Given a sequence of coefficients~$\sequence{f_0, f_1, f_2, \dots}$,
computing the generating function~$F(x)$ is easy since
\begin{equation*}
    F(x) = f_0 + f_1 x + f_2 x^2 + \cdots.
\end{equation*}
To compute the sequence of coefficients from the generating function,
we need to compute the \term{Taylor Series} for the generating
function.

\begin{rul}[Taylor Series]
Let $F(x)$ be the generating function for the sequence
\begin{equation*}
\sequence{f_0, f_1, f_2, \dots}.
\end{equation*}
Then
\begin{equation*}
    f_0 = F(0)
\end{equation*}
and
\begin{equation*}
    f_n = \frac{F^{(n)}(0)}{n!}
\end{equation*}
for $n \ge 1$, where $F^{(n)}(0)$ is the $n$th derivative of~$F(x)$
evaluated at~$x = 0$.
\end{rul}

This is because if
\begin{equation*}
    F(x) = f_0 + f_1 x + f_2 x^2 + \cdots,
\end{equation*}
then
\begin{align*}
    F(0) &= f_0 + f_1 \cdot 0 + f_2 \cdot 0^2 + \cdots \\
         &= f_0.
\end{align*}
Also,
\begin{align*}
F'(x)   &= \frac{d}{dx} (F(x)) \\[\jot]
        &= f_1 + 2 f_2 x + 3 f_3 x^2 + 4 f_4 x^3 + \cdots
\end{align*}
and so
\begin{equation*}
    F'(0) = f_1,
\end{equation*}
as desired.  Taking second derivatives, we find that
\begin{align*}
F''(x)  &= \frac{d}{dx} (F'(x)) \\
        &= 2 f_2 + 3 \cdot 2 f_3 x + 4 \cdot 3 f_4 x^2 + \cdots
\end{align*}
and so
\begin{equation*}
    F''(0) = 2 f_2,
\end{equation*}
which means that
\begin{equation*}
    f_2 = \frac{F''(0)}{2}.
\end{equation*}

In general,
\begin{align*}
F^{(n)}
    &= n! f_n
        + (n + 1)! f_{n + 1} x
        + \frac{(n + 2)!}{2} f_{n + 2} x^2
        + \cdots \\
    & \qquad {} + \frac{(n + k)!}{k!} f_{n + k} x^k
        + \cdots
\end{align*}
and so
\begin{equation*}
    F^{(n)}(0) = n! f_n
\end{equation*}
and
\begin{equation*}
    f_n = \frac{F^{(n)}(0)}{n!},
\end{equation*}
as claimed.

This means that
\begin{equation}\label{eqn:12T}
\ang{ F(0), F'(0), \frac{F''(0)}{2!}, \frac{F'''(0)}{3!}, \dots, 
    \frac{F^{(n)}(0)}{n!}, \dots }
\corresp F(x).
\end{equation}
The sequence on the left-hand side of Equation~\ref{eqn:12T} gives the
well-known Taylor Series expansion for a function
\begin{equation*}
F(x) = F(0) + F'(0) x + \frac{F''(0)}{2!} x^2 +
    \frac{F'''(0)}{3!} x^3 + \cdots + 
    \frac{F^{(n)}(0)}{n!} x^n + \cdots.
\end{equation*}

\subsection{Examples}

Let's try this out on a familiar example:
\begin{equation*}
    F(x) = \frac{1}{1 - x}.
\end{equation*}
Computing derivatives, we find that
\begin{align*}
F'(x)   & = \frac{1}{(1 - x)^2}, \\
F''(x)  & = \frac{2}{(1 - x)^3}, \\
F'''(x) & = \frac{2 \cdot 3}{(1 - x)^4}, \\
        & \enskip\vdots \\
F^{(n)} & = \frac{n!}{(1 - x)^{n + 1}}. 
\end{align*}
This means that the coefficient of~$x^n$ in~$1/(1 - x)$ is
\begin{equation*}
\frac{F^{(n)}(0)}{n!}
    = \frac{n!}{n!\, (1 - 0)^{n + 1}}
    = 1.
\end{equation*}
In other words, we have reconfirmed what we already knew; namely, that
\begin{equation*}
    \frac{1}{1 - x} = 1 + x + x^2 + \cdots.
\end{equation*}

Using a similar approach, we can establish some other well-known
series:
\begingroup
\openup3pt
\begin{align*}
e^x
    &= 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots +
        \frac{x^n}{n!} + \cdots, \\
%
e^{ax}
    &= 1 + ax + \frac{a^2}{2!} x^2 + \frac{a^3}{3!} x^3 + \cdots +
        \frac{a^n}{n!} x^n + \cdots, \\
%
\ln(1 - x)
    &= -a x - \frac{a^2}{2} x^2 - \frac{a^3}{3} x^3 - \cdots 
        - \frac{(-1)^n a^n}{n} x^n - \cdots.
\end{align*}
\endgroup

But what about the series for
\begin{equation}\label{eqn:12D}
    F(x) = \frac{x (1 + x)}{(1 - x)^4} ?
\end{equation}
In particular, we need to know the coefficient of~$x^n$ in~$F(x)$ to
determine
\begin{equation*}
    s_n = \sum_{i = 0}^n i^2.
\end{equation*}

While it is theoretically possible to compute the $n$th derivative
of~$F(x)$, the result is a bloody mess.  Maybe these generating
functions weren't such a great idea after all\dots.

\subsection{Massage Helps}

In times of stress, a little massage can often help relieve the
tension.  The same is true for polynomials with painful derivatives.
For example, let's take a closer look at Equation~\ref{eqn:12D}.  If
we massage it a little bit, we find that
\begin{equation}
F(x)    = \frac{x + x^2}{(1 - x)^4}
        = \frac{x}{(1 - x)^4} + \frac{x^2}{(1 - x)^4}. \label{eqn:12E}
\end{equation}
The goal is to find the coefficient of~$x^n$ in~$F(x)$.  If you stare
at Equation~\ref{eqn:12E} long enough (or if you combine the
Right-Shift Rule with the Addition Rule), you will notice that the
coefficient of~$x^n$ in~$F(x)$ is just the sum of
\begin{gather*}
    \text{the coefficient of~$x^{n - 1}$ in $\frac{1}{(1 - x)^4}$ and}
\\[\smallskipamount]
    \text{the coefficient of~$x^{n - 2}$ in $\frac{1}{(1 - x)^4}$}.
\end{gather*}

Maybe there is some hope after all.  Let's see if we can produce the
coefficients for~$1/(1 - x)^4$.  We'll start by looking at the
derivatives:
\begin{align*}
F'(x)       &= \frac{4}{(1 - x)^5}, \\
F''(x)      &= \frac{4 \cdot 5}{(1 - x)^6}, \\
F'''(x)     &= \frac{4 \cdot 5 \cdot 6}{(1 - x)^7}, \\
            &\enskip \vdots \\
F^{(n)}(x)  &= \frac{(n + 3)!}{ 6 (1 - x)^{n+4} }.
\end{align*}
This means that the $n$th coefficient of~$1/(1 - x)^4$ is
\begin{equation}
\frac{F^{(n)}(0)}{n!}
    = \frac{(n + 3)!}{6 n!} 
    = \frac{(n + 3) (n + 2) (n + 1)}{6}. \label{eqn:12F}
\end{equation}

We are now almost done.  Equation~\ref{eqn:12F} means that the
coefficient of~$x^{n - 1}$ in~$1/(1 - x)^4$ is
\begin{equation}\label{eqn:12G}
    \frac{(n + 2) (n + 1) n}{6}
\end{equation}
and the coefficient\footnote{To be precise, Equation~\ref{eqn:12G}
  holds for $n \ge 1$ and Equation~\ref{eqn:12H} holds for $n \ge 2$.
  But since Equation~\ref{eqn:12G} is~0 for~$n = 1$ and
  Equation~\ref{eqn:12H} is~0 for~$n = 1, 2$, both equations hold for
  all~$n \ge 0$.}  of~$x^{n - 2}$ is
\begin{equation}\label{eqn:12H}
    \frac{(n + 1) n (n - 1)}{6}.
\end{equation}
Adding these values produces the desired sum
\begin{align*}
\sum_{i = 0}^n i^2
    &= \frac{(n + 2) (n + 1) n}{6} + \frac{(n + 1) n (n - 1)}{6} \\
    &= \frac{ (2n + 1) (n + 1) n }{6}.
\end{align*}
This matches Equation~\ref{eqn:G27} from
Chapter~\ref{chap:asymptotics}.  Using generating functions to get the
result may have seemed to be more complicated, but at least there was
no need for guessing or solving a linear system of equations over
4~variables.

You might argue that the massage step was a little tricky.  After all,
how were you supposed to know that by converting~$F(x)$ into the form
shown in Equation~\ref{eqn:12E}, it would be sufficient to compute
derivatives of~$1/(1 - x)^4$, which is easy, instead of derivatives
of~$x (1 + x) / (1 - x)^4$, which could be harder than solving a
64-disk Tower of Hanoi problem step-by-step?

The good news is that this sort of massage works for any generating
function that is a ratio of polynomials.  Even better, you probably
already know how to do it from calculus---it's the method of
\term{partial fractions}!

\subsection{Partial Fractions}\label{sec:partial_fractions}

The idea behind partial fractions is to express a ratio of polynomials
as a sum of a polynomial and terms of the form
\begin{equation}\label{eqn:12R}
    \frac{c x^a}{(1 - \alpha x)^b}
\end{equation}
where $a$ and~$b$ are integers and $b > a \ge 0$.  That's because it
is easy to compute derivatives of~$1/(1 - \alpha x)^b$ and thus it is
easy to compute the coefficients of Equation~\ref{eqn:12R}.  Let's see
why.

\begin{lemma}\label{lem:12A1}
If $b \in \naturals^+$, then the $n$th derivative of~$1/(1 - \alpha
x)^b$ is
\begin{equation*}
    \frac{ (n + b - 1)! \, \alpha^n }{ (b - 1)! \, (1 - \alpha x)^{b + n} }.
\end{equation*}
\end{lemma}

\begin{proof}
The proof is by induction on~$n$.  The induction hypothesis~$P(n)$ is
the statement of the lemma.

\inductioncase{Base case} ($n = 1$): The first derivative is
\begin{equation*}
    \frac{b \alpha}{(1 - \alpha x)^{b + 1}}.
\end{equation*}
This matches
\begin{equation*}
    \frac{(1 + b - 1)!\, \alpha^1}{(b - 1)! \, (1 - \alpha x)^{b + 1}}
    = \frac{b \alpha}{(1 - \alpha x)^{b + 1}},
\end{equation*}
and so $P(1)$ is true.

\inductioncase{Induction step}:
We next assume~$P(n)$ to prove~$P(n + 1)$ for~$n \ge 1$.  $P(n)$
implies that the $n$th derivative of~$1/(1 - \alpha x)^b$ is
\begin{equation*}
    \frac{(n + b - 1)! \, \alpha^n}{(b - 1)! \, (1 - \alpha x)^{b + n}}.
\end{equation*}
Taking one more derivative reveals that the $(n + 1)$st derivative is
\begin{equation*}
\frac{ (n + b - 1)!\, (b + n) \alpha^{n + 1} }
     { (b - 1)!\, (1 - \alpha x)^{b + n + 1} }
  =
\frac{ (n + b)! \, \alpha^{n + 1} }
     { (b - 1)! \, (1 - \alpha x)^{b + n + 1}},
\end{equation*}
which means that $P(n + 1)$~is true.  Hence, the induction is
complete.
\end{proof}

\begin{corollary}\label{cor:12A2}
If $a, b \in \naturals$ and~$b > a \ge 0$, then for any $n \ge a$, the
coefficient of~$x^n$ in
\begin{equation*}
    \frac{c x^a}{(1 - \alpha x)^b}
\end{equation*}
is
\begin{equation*}
    \frac{ c (n - a + b - 1)! \, \alpha^{n - a} }
         { (n - a)! \, (b - 1)! }.
\end{equation*}
\end{corollary}

\begin{proof}
By the Taylor Series Rule, the $n$th coefficient of
\begin{equation*}
    \frac{1}{(1 - \alpha x)^b}
\end{equation*}
is the $n$th derivative of this expression evaluated at~$x = 0$ and
then divided by~$n!$.  By Lemma~\ref{lem:12A1}, this is
\begin{equation*}
\frac{ (n + b - 1)! \, \alpha^n }
     { n! \, (b - 1)! \, (1 - 0)^{b + n} }
  =
\frac{ (n + b - 1)! \, \alpha^n }
     { n! \, (b - 1)! }.
\end{equation*}
By the Scaling Rule and the Right-Shift Rule, the coefficient of~$x^n$
in 
\begin{equation*}
\frac{ c x^\alpha }{ (1 - \alpha x)^b }
\end{equation*}
is thus
\begin{equation*}
    \frac{ c (n - a + b - 1)! \, \alpha^{n - a} }
         { (n - a)! \, (b - 1)! }.
\end{equation*}
as claimed.
\end{proof}

Massaging a ratio of polynomials into a sum of a polynomial and terms
of the form in Equation~\ref{eqn:12R} takes a bit of work but is
generally straightforward.  We will show you the process by means of
an example.

Suppose our generating function is the ratio
\begin{equation}\label{eqn:12T2}
    F(x) = \frac{4 x^3 + 2 x^2 + 3 x + 6}{2 x^3 - 3 x^2 + 1}.
\end{equation}
The first step in massaging~$F(x)$ is to get the degree of the
numerator to be less than the degree of the denominator.  This can be
accomplished by dividing the numerator by the denominator and taking
the remainder, just as in the Fundamental Theorem of Arithmetic---only
now we have polynomials instead of numbers.  In this case we have
\begin{equation*}
\frac{4 x^3 + 2 x^2 + 3 x + 6}{2 x^3 - 3 x^2 + 1}
    = 2 + \frac{8 x^2 + 3 x + 4}{2 x^3 - 3 x^2 + 1}.
\end{equation*}

The next step is to factor the denominator.  This will produce the
values of~$\alpha$ for Equation~\ref{eqn:12R}.  In this case,
\begin{align*}
2 x^3 - 3 x^2 + 1
    &= (2 x + 1) (x^2 - 2 x + 1) \\
    &= (2 x + 1) (x - 1)^2 \\
    &= (1 - x)^2 (1 + 2 x).
\end{align*}

We next find values $c_1$, $c_2$, $c_3$ so that
\begin{equation}\label{eqn:12T3}
\frac{ 8 x^2 + 3 x + 4 }{ 2 x^3 - 3 x^2 + 1 }
    = \frac{c_1}{1 + 2x} + \frac{c_2}{(1 - x)^2} + \frac{c_3 x}{(1 - x)^2}.
\end{equation}
This is done by cranking through the algebra:
\begingroup
\openup 3pt
\begin{align*}
\frac{c_1}{1 + 2x} + \frac{c_2}{(1 - x)^2} + \frac{c_3 x}{(1 - x)^2}
    &= \frac{c_1 (1 - x)^2 + c_2 (1 + 2x) + c_3 x (1 + 2x)}
            {(1 + 2x) (1 - x)^2} \\
    &= \frac{c_1 - 2 c_1 x + c_1 x^2 + c_2 + 2 c_2 x + c_3 x + 2 c_3 x^2}
            {2 x^3 - 3 x^2 + 1} \\
    &= \frac{c_1 + c_2 + (-2 c_1 + 2 c_2 + c_3) x + (c_1 + 2 c_3)x^2}
            {2 x^3 - 3 x^2 + 1}.
\end{align*}
\endgroup
For Equation~\ref{eqn:12T3} to hold, we need
\begin{align*}
    8 &= c_1 + 2 c_3, \\
    3 &= -2 c_1 + 2 c_2 + c_3, \\
    4 &= c_1 + c_2.
\end{align*}
Solving these equations, we find that $c_1 = 2$, \ $c_2 = 2$, and $c_3
= 3$.  Hence,
\begin{align*}
F(x)    &= \frac{ 4 x^3 + 2 x^2 + 3 x + 6 }{2 x^3 - 3 x^2 + 1} \\[2pt]
        &= 2 + \frac{2}{1 + 2x} + \frac{2}{(1 - x)^2} + \frac{3x}{(1 - x)^2}.
\end{align*}

Our massage is done!  We can now compute the coefficients of~$F(x)$
using Corollary~\ref{cor:12A2} and the Sum Rule.  The result is
\begin{equation*}
    f_0 = 2 + 2 + 2 = 6
\end{equation*}
and
\begingroup
\openup 3pt
\begin{align*}
f_n &= \frac{ 2 (n - 0 + 1 - 1)!\, (-2)^{n - 0} }{ (n - 0)! \, (1 - 1)!} \\
&\qquad + \frac{ 2 (n - 0 + 2 - 1)!\, (1)^{n - 0}  }{ (n - 0)! \, (2 - 1)!} \\
&\qquad + \frac{ 3 (n - 1 + 2 - 1)!\, (1)^{n - 1}  }{ (n - 1)! \, (2 - 1)!}\\
    &= (-1)^n 2^{n + 1} + 2 (n + 1) + 3 n \\
    &= (-1)^n 2^{n + 1} + 5 n + 2
\end{align*}
\endgroup
for $n \ge 1$.

Aren't you glad that you know that?  Actually, this method turns out
to be useful in solving linear recurrences, as we'll see in the next
section.

\section{Solving Linear Recurrences}

Generating functions can be used to find a solution to any linear
recurrence.  We'll show you how this is done by means of a familiar
example, the Fibonacci recurrence, so that you can more easily
understand the similarities and differences of this approach and the
method we showed you in Chapter~\ref{chap:recurrences}.

\subsection{Finding the Generating Function}

Let's begin by recalling the definition of the Fibonacci numbers:
%
\begin{align*}
f_0 & = 0 \\
f_1 & = 1 \\
f_n & = f_{n-1} + f_{n-2} \qquad\text{for $n \geq 2$}.
\end{align*}
%
We can expand the final clause into an infinite sequence of equations.
Thus, the Fibonacci numbers are defined by:
%
\begin{align*}
f_0 = & 0 \\
f_1 = & 1 \\
f_2 = & f_1 + f_0 \\
f_3 = & f_2 + f_1 \\
f_4 = & f_3 + f_2 \\
      & \vdots
\end{align*}

The overall plan is to \emph{define} a function $F(x)$ that
generates the sequence on the left side of the equality symbols, which
are the Fibonacci numbers.  Then we \emph{derive} a function that
generates the sequence on the right side.  Finally, we equate the two
and solve for $F(x)$.  Let's try this.  First, we define:
%
\[
    F(x) = f_0 + f_1 x + f_2 x^2 + f_3 x^3 + f_4 x^4 + \cdots.
\]
%
Now we need to derive a generating function for the sequence:
%
\[
    \ang{0,\ 1,\ f_1 + f_0,\ f_2 + f_1,\ f_3 + f_2,\ \dots}.
\]
%
One approach is to break this into a sum of three sequences for which
we know generating functions and then apply the Addition Rule:
%
\[
\begin{array}{@{}c@{}c@{}c@{\,}c@{\,}c@{\,}c@{\,}c@{\,}c@{\,}c@{\;}c@{\;}l}
    & \langle & 0, & 1, & 0, & 0, & 0, & \dots & \rangle
    & \corresp & x \\
    & \langle & 0, & f_0, & f_1, & f_2, & f_3, & \dots & \rangle
    & \corresp & x F(x) \\
{}+{} & \langle & 0, & 0, & f_0, & f_1, & f_2, & \dots & \rangle
    & \corresp & x^2 F(x) \\[2pt] \hline\noalign{\vskip2pt}
    & \langle & 0, & 1 + f_0, & f_1 + f_0, & f_2 + f_1, & f_3 + f_2, & \dots & \rangle
    & \corresp & x + x F(x) + x^2 F(x) \\
\end{array}
\]
%
This sequence is almost identical to the right sides of the Fibonacci
equations.  The one blemish is that the second term is $1 + f_0$
instead of simply 1.  However, this amounts to nothing, since $f_0 =
0$ anyway.

If we equate $F(x)$ with the new function $x + x F(x) + x^2 F(x)$,
then we're implicitly writing down \emph{all} of the equations that
define the Fibonacci numbers in one fell swoop:
%
\[
\begin{array}{c@{\;}c@{\;}c@{\,}c@{\,}c@{}c@{\,}c@{\,}c@{}c@{\,}c@{\,}c@{}c@{\,}c@{\,}c}
F(x)
    & = & f_0 & + & f_1 & x & + & f_2 & x^2 & + & f_3 & x^3 & + \cdots \\
\shortparallel && \shortparallel && \shortparallel &&& \shortparallel &&& \shortparallel\\
x + x F(x) + x^2 F(x)
    & = & 0 & + & (1 + f_0) & x & + & (f_1 + f_0) & x^2 & + & (f_2 + f_1) & x^3 & + \cdots
\end{array}
\]
%
Solving for $F(x)$ gives the generating function for the Fibonacci
sequence:
%
\[
F(x)  = x + x F(x) + x^2 F(x)
\]
so
\begin{equation}\label{eqn:12T4}
F(x) = \frac{x}{1 - x - x^2}.
\end{equation}

This is pretty cool.  After all, who would have thought that the
Fibonacci numbers are precisely the coefficients of such a simple
function?  Even better, this function is a ratio of polynomials and so
we can use the method of partial fractions from
Section~\ref{sec:partial_fractions} to find a closed-form
expression for the $n$th Fibonacci number.

\subsection{Extracting the Coefficients}

Repeated differentiation of Equation~\ref{eqn:12T4} would be very
painful.  But it is easy to use the method of partial fractions to
compute the coefficients.  Since the degree of the numerator in
Equation~\ref{eqn:12T4} is less than the degree of the denominator,
the first step is to factor the denominator:
\begin{equation*}
    1 - x - x^2 = (1 - \alpha_1 x) (1 - \alpha_2 x)
\end{equation*}
where $\alpha_1 = (1 + \sqrt{5})/2$ and $\alpha_2 = (1 - \sqrt{5})/2$.
These are the same as the roots of the characteristic equation for the
Fibonacci recurrence that we found in Chapter~\ref{chap:recurrences}.
That is not a coincidence.

The next step is to find $c_1$ and~$c_2$ that satisfy
\begingroup
\openup 3pt
\begin{align*}
\frac{x}{1 - x - x^2}
    &= \frac{c_1}{1 - \alpha_1 x} + \frac{c_2}{1 - \alpha_2 x} \\
    &= \frac{c_1 (1 - \alpha_2 x) + c_2 (1 - \alpha_1 x)}
            {(1 - \alpha_1 x) (1 - \alpha_2 x)} \\
    &= \frac{c_1 + c_2 - (c_1 \alpha_2 + c_2 \alpha_1 x)}
            {1 - x - x^2}.
\end{align*}
\endgroup
Hence,
\begin{equation*}
    c_1 + c_2 = 0
    \qquad\text{and}\qquad
    - (c_1 \alpha_2 + c_2 \alpha_1) = 1.
\end{equation*}
Solving these equations, we find that
\begin{align*}
    c_1 &= \frac{1}{\alpha_1 - \alpha_2} = \frac{1}{\sqrt{5}} \\
    c_2 &= \frac{-1}{\alpha_1 - \alpha_2} = \frac{-1}{\sqrt{5}}.
\end{align*}

We can now use Corollary~\ref{cor:12A2} and the Sum Rule to conclude
that
\begin{align*}
f_n &= \frac{\alpha_1^n}{\sqrt{5}} - \frac{\alpha_2^n}{\sqrt{5}} \\[3pt]
    &= \frac{1}{\sqrt{5}}
        \paren{
            \paren{\frac{1 + \sqrt{5}}{2}}^n - \paren{\frac{1 - \sqrt{5}}{2}}^n
        }.
\end{align*}
This is exactly the same formula we derived for the $n$th Fibonacci
number in Chapter~\ref{chap:recurrences}.

\subsection{General Linear Recurrences}

The method that we just used to solve the Fibonacci recurrence can
also be used to solve general linear recurrences of the form
\begin{equation*}
    f_n = a_1 f_{n - 1} + a_2 f_{n - 2} + \dots + a_d f_{n - d} + g_n
\end{equation*}
for~$n \ge d$.  The generating function for~$\sequence{f_0, f_1, f_2,
  \dots}$ is
\begin{equation*}
F(x) = \frac{ h(x) + G(x) }{ 1 - a_1 x - a_2 x^2 - \dots - a_d x^d }
\end{equation*}
where $G(x)$~is the generating function for the sequence
\begin{equation*}
    \sequence{ \overbrace{0, 0, \dots, 0}^d, g_d, g_{d + 1}, g_{d +
        2}, \dots }
\end{equation*}
and $h(x)$~is a polynomial of degree at most~$d - 1$ that is based on
the values of~$f_0$, $f_1$, \dots, $f_{d - 1}$.  In particular,
\begin{equation*}
    h(x) = \sum_{i = 0}^{d - 1} h_i x^i
\end{equation*}
where
\begin{equation*}
    h_i = f_0 - a_1 f_{i - 1} - a_2 f_{i - 2} - \dots - a_i f_0
\end{equation*}
for~$0 \le i < d$.

To solve the recurrence, we use the method of partial fractions
described in Section~\ref{sec:partial_fractions} to find a closed-form
expression for~$F(x)$.  This can be easy or hard to do depending
on~$G(x)$.

\begin{problems}
\classproblems
\pinput{CP_Fibonacci_and_bunnies}
\pinput{CP_towers_of_Sheboygan}

\homeworkproblems
\pinput{PS_gen_fcn_quotient_polynomials}

\end{problems}

\section{Counting with Generating Functions}

Generating functions are particularly useful for solving counting
problems.  In particular, problems involving choosing items from a set
often lead to nice generating functions by letting the coefficient of
$x^n$ be the number of ways to choose $n$ items.

\subsection{Choosing Distinct Items from a Set}

The generating function for binomial coefficients follows directly
from the \idx{Binomial Theorem}:
%
\begin{align*}
\ang{\textstyle \binom{k}{0}, \binom{k}{1}, \binom{k}{2}, \dots, \binom{k}{k},
        0, 0, 0, \dots }
    & \corresp \textstyle \binom{k}{0} + \binom{k}{1} x + \binom{k}{2} x^2 + \cdots + \binom{k}{k} x^k \\
    & = (1 + x)^k
\end{align*}
Thus, the coefficient of $x^n$ in $(1 + x)^k$ is $\binom{k}{n}$, the
number of ways to choose $n$ distinct items\footnote{Watch out for the
  reversal of the roles that $k$ and $n$ played in earlier examples;
  we're led to this reversal because we've been using $n$ to refer to
  the power of $x$ in a power series.}  from a set of size $k$.  For
example, the coefficient of $x^2$ is $\binom{k}{2}$, the number of
ways to choose 2 items from a set with $k$ elements.  Similarly, the
coefficient of $x^{k+1}$ is the number of ways to choose $k+1$ items
from a size $k$ set, which is zero.

\subsection{Building Generating Functions that Count}

Often we can translate the description of a counting problem directly
into a generating function for the solution.  For example, we could
figure out that $(1 + x)^k$ generates the number of ways to select $n$
distinct items from a $k$-element set without resorting to the
Binomial Theorem or even fussing with binomial coefficients!  Let's
see how.

First, consider a single-element set $\set{a_1}$.  The
generating function for the number of ways to select $n$ elements from
this set is simply $1 + x$: we have 1 way to select zero elements, 1
way to select one element, and 0 ways to select more than one element.
Similarly, the number of ways to select $n$ elements from the set
$\set{a_2}$ is also given by the generating function $1 + x$.  The
fact that the elements differ in the two cases is irrelevant.

Now here is the main trick: \emph{the generating function for choosing
  elements from a union of disjoint sets is the product of the
  generating functions for choosing from each set.}  We'll justify
this in a moment, but let's first look at an example.  According to
this principle, the generating function for the number of ways to
select $n$ elements from the $\set{a_1, a_2}$ is:
%
\[
\underbrace{(1 + x)}_{\textstyle\text{select from $\set{a_1}$}}
\cdot
\underbrace{(1 + x)}_{\textstyle\text{select from $\set{a_2}$}}
=
\underbrace{(1 + x)^2}_{\textstyle\text{select from $\set{a_1, a_2}$}}
= 1 + 2x + x^2.
\]
%
Sure enough, for the set $\set{a_1, a_2}$, we have 1 way to select
zero elements, 2 ways to select one element, 1 way to select two
elements, and 0 ways to select more than two elements.

Repeated application of this rule gives the generating function for
selecting $n$ items from a $k$-element set $\set{a_1, a_2, \dots,
a_k}$:
%
\[
\underbrace{(1 + x)}_{\textstyle\text{select from $\set{a_1}$}}
\cdot
\underbrace{(1 + x)}_{\textstyle\text{select from $\set{a_2}$}}
\cdots
\underbrace{(1 + x)}_{\textstyle\text{select from $\set{a_k}$}}
=
\underbrace{(1 + x)^k}_{
\begin{array}{cc}
\text{select from} \\
\set{a_1, a_2, \dots, a_k}
\end{array}}
\]
%
This is the same generating function that we obtained by using the
Binomial Theorem.  But this time around, we translated directly from
the counting problem to the generating function.

We can extend these ideas to a general principle:

% This is hand wavy and could use improvement.  I hope they get the idea.

\begin{rul}[\idx{Convolution Rule}]
Let $A(x)$ be the generating function for selecting items from set
${\cal A}$, and let $B(x)$ be the generating function for selecting
items from set ${\cal B}$.  If ${\cal A}$ and ${\cal B}$ are disjoint,
then the generating function for selecting items from the union ${\cal
A} \cup {\cal B}$ is the product $A(x) \cdot B(x)$.
\end{rul}

This rule is rather ambiguous: what exactly are the rules governing
the selection of items from a set?  Remarkably, the Convolution Rule
remains valid under \emph{many} interpretations of selection.  For
example, we could insist that distinct items be selected or we might
allow the same item to be picked a limited number of times or any
number of times.  Informally, the only restrictions are that (1) the
order in which items are selected is disregarded and (2) restrictions
on the selection of items from sets ${\cal A}$ and ${\cal B}$ also
apply in selecting items from ${\cal A} \cup {\cal B}$.  (Formally,
there must be a bijection between $n$-element selections from ${\cal
A} \cup {\cal B}$ and ordered pairs of selections from ${\cal A}$ and
${\cal B}$ containing a total of $n$ elements.)

To count the number of ways to select $n$ items from ${\cal A} \cup {\cal
B}$, we observe that we can select $n$ items by choosing $j$ items from
${\cal A}$ and $n - j$ items from ${\cal B}$, where $j$ is any number from
0 to $n$.  This can be done in $a_j b_{n-j}$ ways.  Summing over all the
possible values of $j$ gives a total of
\[
a_0 b_n + a_1 b_{n-1} + a_2 b_{n-2} + \cdots + a_n b_0
\]
ways to select $n$ items from ${\cal A} \cup {\cal B}$.  By the Product
Rule, this is precisely the coefficient of $x^n$ in the series for
$A(x)B(x)$.


\subsection{Choosing Items with Repetition}
\label{sec:rep}

The first counting problem we considered was the number of ways to
select a dozen doughnuts when five flavors were available.  We can
generalize this question as follows: in how many ways can we select
$n$ items from a $k$-element set if we're allowed to pick the same
item multiple times?  In these terms, the doughnut problem asks how
many ways we can select $n=12$ doughnuts from the set of $k=5$ flavors
\[
\set{\text{chocolate}, \text{lemon-filled}, \text{sugar}, \text{glazed}, \text{plain}}
\]
%
where, of course, we're allowed to pick several doughnuts of the same
flavor.   Let's approach this question from a generating functions
perspective.

Suppose we make $n$~choices (with repetition allowed) of items from a set
containing a single item.  Then there is one way to choose zero items, one
way to choose one item, one way to choose two items, etc.  Thus, the
generating function for choosing $n$ elements with repetition from a
1-element set is:
%
\begin{align*}
\ang{1, 1, 1, 1, \dots}
     & \corresp  1 + x + x^2 + x^3 + \cdots %\\
     %&
 =  \frac{1}{1-x}.
\end{align*}

\dmj{I changed these labels for closer correspondence with the changed
  labels above.}
The Convolution Rule says that the generating function for selecting
items from a union of disjoint sets is the product of the generating
functions for selecting items from each set:
%
\[
\underbrace{\frac{1}{1-x}}_{\textstyle\text{choose $a_1$'s}}
\cdot
\underbrace{\frac{1}{1-x}}_{\textstyle\text{choose $a_2$'s}}
\cdots
\underbrace{\frac{1}{1-x}}_{\textstyle\text{choose $a_k$'s}}
=
\underbrace{\frac{1}{(1-x)^k}}_{
\begin{array}{cc}
\text{repeatedly choose from} \\
\set{a_1, a_2, \dots, a_k}
\end{array}}
\]
%
Therefore, the generating function for choosing items from a
$k$-element set with repetition allowed is $1 / (1 - x)^k$.  Computing
derivatives and applying the Taylor Series Rule, we can find that the
coefficient of~$x^n$ in~$1 / (1 - x)^k$ is
\[
    \binom{n+k-1}{n}.
\]
This is the Bookkeeper Rule from Chapter~\ref{counting_chap}---namely
there are $\binom{n + k - 1}{n}$~ways to select $n$~items with
replication from a set of $k$~items.


\begin{problems}
\practiceproblems
\pinput{MQ_bouquet}

\classproblems
\pinput{CP_nth_derivative_of_A}
\pinput{CP_bag_of_donuts}
\pinput{CP_gen_func_sum_of_squares}

\homeworkproblems
\pinput{PS_gen_fcns_pennies_nickels_etc}

\examproblems
\pinput{MQ_gen_2}
%\pinput{MQ_binomial_coef}

\end{problems}

\subsection{Fruit Salad}

In this chapter, we have covered a lot of methods and rules for using
generating functions.  We'll now do an example that demonstrates how
the rules and methods can be combined to solve a more challenging
problem---making fruit salad.

In how many ways can we make a salad with $n$~fruits subject to the
following constraints?
\begin{itemize}
\item The number of apples must be even.
\item The number of bananas must be a multiple of 5.
\item There can be at most four oranges.
\item There can be at most one pear.
\end{itemize}

For example, there are 7 ways to make a salad with 6 fruits:
%
\[
\begin{array}{c|ccccccc}
\text{Apples}  & 6 & 4 & 4 & 2 & 2 & 0 & 0 \\
\text{Bananas} & 0 & 0 & 0 & 0 & 0 & 5 & 5 \\
\text{Oranges} & 0 & 2 & 1 & 4 & 3 & 1 & 0 \\
\text{Pears}   & 0 & 0 & 1 & 0 & 1 & 0 & 1
\end{array}
\]
%
These constraints are so complicated that the problem seems hopeless!
But generating functions can solve the problem in a straightforward
way.

Let's first construct a generating function for choosing apples.  We
can choose a set of 0~apples in one way, a set of 1~apple in zero
ways (since the number of apples must be even), a set of 2~apples in
one way, a set of 3~apples in zero ways, and so forth.  So we have:
%
\[
    A(x) = 1 + x^2 + x^4 + x^6 + \cdots = \frac{1}{1 - x^2}.
\]
%
Similarly, the generating function for choosing bananas is:
%
\[
    B(x) = 1 + x^5 + x^{10} + x^{15} + \cdots = \frac{1}{1 - x^5}.
\]
We can choose a set of 0~oranges in one way, a set of 1~orange in
one way, and so on.  However, we can not choose more than four
oranges, so we have the generating function:
%
\[
    O(x) = 1 + x + x^2 + x^3 + x^4 = \frac{1-x^5}{1-x}.
\]
%
Here we're using the geometric sum formula.  Finally, we can choose
only zero or one pear, so we have:
%
\[
    P(x) = 1 + x.
\]

The Convolution Rule says that the generating function for choosing
from among all four kinds of fruit is:
%
\begin{align*}
A(x) B(x) O(x) P(x)
    & = \frac{1}{1-x^2} \frac{1}{1-x^5} \frac{1-x^5}{1-x} (1 + x) \\
    & = \frac{1}{(1-x)^2} \\
    & = 1 + 2x + 3x^2 + 4 x^3 + \cdots.
\end{align*}
%
Almost everything cancels!  We're left with $1 / (1-x)^2$, which we
found a power series for earlier: the coefficient of $x^n$ is simply
$n+1$.  Thus, the number of ways to make a salad with $n$~fruits is
just $n+1$.  This is consistent with the example we worked out at the
start, since there were 7~different salads containing 6~fruits.
\emph{Amazing!}

\begin{problems}
\practiceproblems
\pinput{TP_Counting_with_Generating_Functions}
\pinput{TP_Generating_Functions_and_Sequences}

\homeworkproblems
\pinput{PS_crazy_pet_lady}

%PS_gen_fcns_with_donuts DRAFT in unused

\pinput{PS_Catalan_numbers_meyer_version}

\examproblems
\pinput{FP_boat_trip}

\end{problems}

\problemsection

\endinput
