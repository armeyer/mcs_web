\chapter{Events and Probability Spaces}\label{probability_chap}

\section{Let's Make a Deal}

In the September 9, 1990 issue of \emph{Parade} magazine, columnist
Marilyn vos Savant responded to this letter:

%  future:
%  Include the other problem that Marilyn addressed in the same issue.

\begin{quote}
\emph{Suppose you're on a game show, and you're given the
choice of three doors.  Behind one door is a car, behind the others,
goats.  You pick a door, say number 1, and the host, who knows what's
behind the doors, opens another door, say number 3, which has a goat.
He says to you, "Do you want to pick door number 2?"  Is it to your
advantage to switch your choice of doors?}
\begin{flushright}
\begin{tabular}{l}
Craig. F. Whitaker \\
Columbia, MD
\end{tabular}
\end{flushright}
\end{quote}

The letter describes a situation like one faced by contestants on the
1970's game show \emph{Let's Make a Deal}, hosted by Monty Hall and
Carol Merrill.  Marilyn replied that the contestant should indeed
switch.  She explained that if the car was behind either of the two
unpicked doors---which is twice as likely as the the car being behind
the picked door---the contestant wins by switching.  But she soon
received a torrent of letters, many from mathematicians, telling her
that she was wrong.  The problem became known as the \term{Monty Hall
  Problem} and it generated thousands of hours of heated debate.

This incident highlights a fact about probability: the subject uncovers
lots of examples where ordinary intuition leads to completely wrong
conclusions.  So until you've studied probabilities enough to have
refined your intuition, a way to avoid errors is to fall back on a
rigorous, systematic approach such as the Four Step Method that we
will describe shortly.  First, let's make sure we really understand
the setup for this problem.  This is always a good thing to do when
you are dealing with probability.

\subsection{Clarifying the Problem}

Craig's original letter to Marilyn vos Savant is a bit vague, so we
must make some assumptions in order to have any hope of modeling the
game formally.  For example, we will assume that:
\begin{enumerate}

\item The car is equally likely to be hidden behind each of the three
doors.

\item The player is equally likely to pick each of the three doors,
regardless of the car's location.

\item After the player picks a door, the host \emph{must} open a
different door with a goat behind it and offer the player the choice
of staying with the original door or switching.

\item If the host has a choice of which door to open, then he is
equally likely to select each of them.

\end{enumerate}
%
In making these assumptions, we're reading a lot into Craig Whitaker's
letter.  Other interpretations are at least as defensible, and some
actually lead to different answers.  But let's accept these
assumptions for now and address the question, ``What is the
probability that a player who switches wins the car?''

\section{The Four Step Method}

Every probability problem involves some sort of randomized experiment,
process, or game.  And each such problem involves two distinct
challenges:
%
\begin{enumerate}
\item How do we model the situation mathematically?
\item How do we solve the resulting mathematical problem?
\end{enumerate}
%
In this section, we introduce a four step approach to questions of the
form, ``What is the probability that\dots?''  In this approach, we build
a probabilistic model step-by-step, formalizing the original question in
terms of that model.  Remarkably, the structured thinking that this
approach imposes provides simple solutions to many famously-confusing
problems.  For example, as you'll see, the four step method cuts through
the confusion surrounding the Monty Hall problem like a Ginsu knife.
More complex probability questions may spin off challenging
counting, summing, and approximation problems---which, fortunately,
you've already spent weeks learning how to solve.


\subsection{Step 1:  Find the Sample Space}

Our first objective is to identify all the possible outcomes of the
experiment.  A typical experiment involves several randomly-determined
quantities.  For example, the Monty Hall game involves three such
quantities:
%
\begin{enumerate}
\item The door concealing the car.
\item The door initially chosen by the player.
\item The door that the host opens to reveal a goat.
\end{enumerate}
%
Every possible combination of these randomly-determined quantities is
called an \term{outcome}.  The set of all possible outcomes is called
the \term{sample space} for the experiment.

A \term{tree diagram} is a graphical tool that can help us work
through the four step approach when the number of outcomes is not too
large or the problem is nicely structured.  In particular, we can use
a tree diagram to help understand the sample space of an experiment.
The first randomly-determined quantity in our experiment is the door
concealing the prize.  We represent this as a tree with three
branches, as shown in Figure~\ref{fig:14A1}.  In this diagram, the
doors are called $A$, $B$, and $C$ instead of 1, 2, and 3, because
we'll be adding a lot of other numbers to the picture later.

\begin{figure}[h]

\graphic[height=2.5in]{monty1}

\caption{The first level in a tree diagram for the Monty Hall
  Problem.  The branches correspond to the door behind which the car
  is located.}

\label{fig:14A1}

\end{figure}

For each possible location of the prize, the player could initially
choose any of the three doors.  We represent this in a second layer
added to the tree.  Then a third layer represents the possibilities of
the final step when the host opens a door to reveal a goat, as shown
in Figure~\ref{fig:14A2}.

\begin{figure}

\gnote{This figure is the same as \ref{fig:14A3} but without the
  ``outcome'' column of data.}

\graphic{monty2-new}

\caption{The full tree diagram for the Monty Hall Problem.  The second
level indicates the door initially chosen by the player.  The third
level indicates the door revealed by Monty Hall.}

\label{fig:14A2}

\end{figure}

Notice that the third layer reflects the fact that the host has either one
choice or two, depending on the position of the car and the door initially
selected by the player.  For example, if the prize is behind door A and
the player picks door B, then the host must open door C.  However, if the
prize is behind door A and the player picks door A, then the host could
open either door B or door C.

\begin{figure}

\graphic[height=4.0in]{monty3}

\caption{The tree diagram for the Monty Hal Problem with the outcomes
  labeled for each path from root to leaf.  For example, outcome $(A,
  A, B)$ corresponds to the car being behind door~$A$, the player
  initially choosing door~$A$, and Monty Hall revealing the goat
  behind door~$B$.}

\label{fig:14A3}

\end{figure}

Now let's relate this picture to the terms we introduced earlier: the
leaves of the tree represent \emph{outcomes} of the experiment, and
the set of all leaves represents the \emph{sample space}.  Thus, for
this experiment, the sample space consists of 12 outcomes.  For
reference, we've labeled each outcome in Figure~\ref{fig:14A3} with a
triple of doors indicating:
%
\[
    (\text{door concealing prize}, \;
    \text{door initially chosen}, \;
     \text{door opened to reveal a goat}).
\]
%
In these terms, the sample space is the set
%
\[
\sspace = \left\{
\begin{array}{cccccc}
(A, A, B), & (A, A, C), & (A, B, C), & (A, C, B), & (B, A, C), & (B, B, A), \\
(B, B, C), & (B, C, A), & (C, A, B), & (C, B, A), & (C, C, A), & (C, C, B)
\end{array}
\right\}
\]
%
The tree diagram has a broader interpretation as well: we can regard the
whole experiment as following a path from the root to a leaf, where the
branch taken at each stage is ``randomly'' determined.  Keep this
interpretation in mind; we'll use it again later.

\subsection{Step 2: Define Events of Interest}

Our objective is to answer questions of the form ``What is the
probability that \dots ?'', where, for example, the missing phrase
might be ``the player wins by switching'', ``the player initially
picked the door concealing the prize'', or ``the prize is behind door
C''.  Each of these phrases characterizes a set of outcomes. For
example, the outcomes specified by ``the prize is behind door $C$''
is:
%
\[
\set{(C, A, B), (C, B, A), (C, C, A), (C, C, B)}
\]
%
A set of outcomes is called an \term{event} and it is a subset of the
sample space.  So the event that the player initially picked the door
concealing the prize is the set:
%
\[
\set{(A, A, B), (A, A, C), (B, B, A), (B, B, C), (C, C, A), (C, C, B)}
\]
%
And what we're really after, the event that the player wins by
switching, is the set of outcomes:
%
\[
\set{(A, B, C), (A, C, B), (B, A, C), (B, C, A), (C, A, B), (C, B, A)}
\]
These outcomes are denoted with a check mark in Figure~\ref{fig:14A4}.

\begin{figure}

\graphic[height=3.5in]{monty4}

\caption{The tree diagram for the Monty Hall Problem where the
  outcomes in the event where player wins by switching are denoted
  with a check mark.}

\label{fig:14A4}

\end{figure}

Notice that exactly half of the outcomes are checked, meaning that the
player wins by switching in half of all outcomes.  You might be
tempted to conclude that a player who switches wins with probability
$1/2$.  \emph{This is wrong.}  The reason is that these outcomes are
not all equally likely, as we'll see shortly.

\subsection{Step 3: Determine Outcome Probabilities}

So far we've enumerated all the possible outcomes of the experiment.  Now
we must start assessing the likelihood of those outcomes.  In particular,
the goal of this step is to assign each outcome a probability, indicating
the fraction of the time this outcome is expected to occur.  The sum of
all outcome probabilities must be one, reflecting the fact that there
always is an outcome.

Ultimately, outcome probabilities are determined by the phenomenon
we're modeling and thus are not quantities that we can derive
mathematically.  However, mathematics can help us compute the
probability of every outcome \emph{based on fewer and more
elementary modeling decisions.}  In particular, we'll break the task
of determining outcome probabilities into two stages.

\subsubsection{Step 3a: Assign Edge Probabilities}

First, we record a probability on each \emph{edge} of the tree
diagram.  These edge-probabilities are determined by the assumptions
we made at the outset: that the prize is equally likely to be behind
each door, that the player is equally likely to pick each door, and
that the host is equally likely to reveal each goat, if he has a
choice.  Notice that when the host has no choice regarding which door
to open, the single branch is assigned probability 1.  For example,
see Figure~\ref{fig:14A5}.

\begin{figure}[h]

\graphic[height=3.5in]{monty5}

\caption{The tree diagram for the Monty Hall Problem where edge
  weights denote the probability of that branch being taken given that
we are at the parent of that branch.  For example, if the car is
behind door~$A$, there is a 1/3 chance that the player's initial
selection is door~$B$.}

\label{fig:14A5}

\end{figure}

\subsubsection{Step 3b: Compute Outcome Probabilities}

Our next job is to convert edge probabilities into outcome
probabilities.  This is a purely mechanical process: \emph{the
probability of an outcome is equal to the product of the
edge-probabilities on the path from the root to that outcome}.  For
example, the probability of the topmost outcome, $(A, A, B)$ is
\[
\frac{1}{3} \cdot \frac{1}{3} \cdot \frac{1}{2} = \frac{1}{18}.
\]

There's an easy, intuitive justification for this rule.  As the steps in
an experiment progress randomly along a path from the root of the tree to
a leaf, the probabilities on the edges indicate how likely the path is to
proceed along each branch.  For example, a path starting at the root in
our example is equally likely to go down each of the three top-level
branches.

How likely is such a path to arrive at the topmost outcome, $(A,
A, B)$?  Well, there is a 1-in-3 chance that a path would follow the
$A$-branch at the top level, a 1-in-3 chance it would continue along
the $A$-branch at the second level, and 1-in-2 chance it would follow
the $B$-branch at the third level.  Thus, it seems that about 1~path
in~18 should arrive at the $(A, A, B)$ leaf, which is precisely the
probability we assign it.

We have illustrated all of the outcome probabilities in
Figure~\ref{fig:14A6}.

\begin{figure}[h]

\graphic[height=3.5in]{monty6}

\caption{The rightmost column shows the outcome probabilities for the
  Monty Hall Problem.  Each outcome probability is simply the product
  of the probabilities on the branches on the path from the root to th
  leaf for that outcome.}

\label{fig:14A6}
\end{figure}

Specifying the probability of each outcome amounts to defining a
function that maps each outcome to a probability.  This function is
usually called \textbf{Pr}.  In these terms, we've just determined
that:
%
\begin{align*}
\pr{(A, A, B)} & = \frac{1}{18} \\
\pr{(A, A, C)} & = \frac{1}{18} \\
\pr{(A, B, C)} & = \frac{1}{9} \\
               & \text{etc.}
\end{align*}

\subsection{Step 4: Compute Event Probabilities}

We now have a probability for each \emph{outcome}, but we want to
determine the probability of an \emph{event}.  The probability of an
event~$E$ is denoted by $\pr{E}$ and it is the sum of the
probabilities of the outcomes in~$E$.  For example, the probability of
the event that the player wins by switching is:\footnote{``Switching
  wins'' is shorthand for the set of outcomes where switching wins;
  namely, $\set{ (A, B, C),\, (A, C, B),\, (B, A, C), \, (B, C, A), \,
    (C, A, B), \, (C, B, A) }$. We will frequently use such shorthand
  to denote events.}
%
\begin{align*}
\pr{\text{switching wins}}
    & = \pr{(A, B, C)} + \pr{(A, C, B)} + \pr{(B, A, C)} + \\
    & \qquad \pr{(B, C, A)} + \pr{(C, A, B)} + \pr{(C, B, A)} \\
    & = \frac{1}{9} + \frac{1}{9} + \frac{1}{9} +
        \frac{1}{9} + \frac{1}{9} + \frac{1}{9} \\
    & = \frac{2}{3}
\end{align*}
%
It seems Marilyn's answer is correct!  A player who switches doors
wins the car with probability~$2/3$.  In contrast, a player who stays
with his or her original door wins with probability $1/3$, since
staying wins if and only if switching loses.

We're done with the problem!  We didn't need any appeals to intuition
or ingenious analogies.  In fact, no mathematics more difficult than
adding and multiplying fractions was required.  The only hard part was
resisting the temptation to leap to an ``intuitively obvious'' answer.

\subsection{An Alternative Interpretation of the Monty Hall Problem}

Was Marilyn really right?  Our analysis indicates that she was.  But a
more accurate conclusion is that her answer is correct \emph{provided
  we accept her interpretation of the question}.  There is an equally
plausible interpretation in which Marilyn's answer is wrong.  Notice
that Craig Whitaker's original letter does not say that the host is
\emph{required} to reveal a goat and offer the player the option to
switch, merely that he \emph{did} these things.  In fact, on the
\emph{Let's Make a Deal} show, Monty Hall sometimes simply opened the
door that the contestant picked initially.  Therefore, if he wanted
to, Monty could give the option of switching only to contestants who
picked the correct door initially.  In this case, switching never
works!

%% Monty Hall Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{problems}
\classproblems
\pinput{CP_a_baseball_series}
\pinput{CP_coin_flips}
\pinput{CP_the_four_door_deal}
\pinput{CP_simulating_fair_coin}

\homeworkproblems
\pinput{PS_black_and_red_cards}

\end{problems}

\section{Strange Dice}

The four-step method is surprisingly powerful.  Let's get some more
practice with it.  Imagine, if you will, the following scenario.

It's a typical Saturday night.  You're at your favorite pub,
contemplating the true meaning of infinite cardinalities, when a
burly-looking biker plops down on the stool next to you.  Just as you
are about to get your mind around~$\power(\power(\reals))$, biker dude
slaps three strange-looking dice on the bar and challenges you to a
\$100 wager.

The rules are simple.  Each player selects one die and rolls it once.
The player with the lower value pays the other player~\$100.

Naturally, you are skeptical.  A quick inspection reveals that these
are not ordinary dice.  They each have six sides, but the numbers on
the dice are different, as shown in Figure~\ref{fig:14A7}.

\begin{figure}

\graphic{Fig_A7}

\caption{\emph{The strange dice}.  The number on each concealed face
  is the same as the number on the opposite face.  For example, when
  you roll die~$A$, the probabilities of getting a 2, 6, or~7 are
  each~$1/3$.}

\label{fig:14A7}

\end{figure}

Biker dude notices your hesitation and so he offers to let you pick a
die first, and then he will choose his die from the two that are
left.  That seals the deal since you figure that you now have an
advantage.

But which of the dice should you choose?  Die~$B$ is appealing because
it has a~9, which is a sure winner if it comes up.  Then again,
die~$A$ has two fairly large numbers and die~$B$ has an~8 and no
really small values.

In the end, you choose die~$B$ because has a~9 and then biker dude
selects die~$A$.  Let's see what the probability is that you will
win.\footnote{Of course, you probably should have done this before
  picking die~$B$ in the first place.}
Not surprisingly, we will use the four-step method to compute this
probability.

\subsection{Die~$A$ versus Die~$B$}

\paragraph{Step 1: Find the sample space.}

The sample space for this experiment is worked out in the tree diagram
shown in Figure~\ref{fig:14A8}.\footnote{Actually, the whole
  probability space is worked out in this one picture.  But pretend
  that each component sort of fades in---nyyrrroom!---as you read
  about the corresponding step below.}

\begin{figure}

\graphic{Fig_A8}

\caption{The tree diagram for one roll of die~$A$ versus die~$B$.
  Die~$A$ wins with probability~$5/9$.}

\label{fig:14A8}

\end{figure}

For this experiment, the sample space is a set of nine outcomes:
\begin{equation*}
\sspace = \set{\, (2, 1), \, (2, 5), \, (2, 9), \,
                  (6, 1), \, (6, 5), \, (6, 9), \,
                  (7, 1), \, (7, 5), \, (7, 9) \,}.
\end{equation*}

\paragraph{Step 2: Define events of interest.}

We are interested in the event that the number on die~$A$ is greater
than the number on die~$B$.  This event is a set of five outcomes:
\begin{equation*}
    \set{\, (2, 1), \, (6, 1), \, (6, 5), \, (7, 1), \, (7, 5) \,}.
\end{equation*}
These outcomes are marked~$A$ in the tree diagram in
Figure~\ref{fig:14A8}.

\paragraph{Step 3: Determine outcome probabilities.}

To find outcome probabilities, we first assign probabilities to edges
in the tree diagram.  Each number on each die comes up with
probability~$1/3$, regardless of the value of the other die.
Therefore, we assign all edges probability~$1/3$.  The probability of
an outcome is the product of the probabilities on the corresponding
root-to-leaf path, which means that every outcome has
probability~$1/9$.  These probabilities are recorded on the right side
of the tree diagram in Figure~\ref{fig:14A8}.

\paragraph{Step 4: Compute event probabilities.}

The probability of an event is the sum of the probabilities of the
outcomes in that event.  Therefore, the probability that die~$A$ comes
up greater than die~$B$ is
\begin{align*}
\pr{A > B}
    &= \pr{(2, 1)} + \pr{(6, 1)} + \pr{(6, 5)} + \pr{(7, 1)} + \pr{(7, 5)} \\
    &= \frac{1}{9} + \frac{1}{9} + \frac{1}{9} + \frac{1}{9} + \frac{1}{9} \\
    &= \frac{5}{9}.
\end{align*}

In this case, all the outcome probabilities are the same.  In general,
when the probability of every outcome is the same, we say that the
sample space is \term{uniform}.  Computing event probabilities for
uniform sample spaces is particularly easy since you just have to
compute the number of outcomes in the event.  In particular, for any
event~$E$ in a uniform sample space~$\sspace$,
\begin{equation}\label{eqn:14F1}
    \pr{E} = \frac{\card{E}}{\card{\sspace}}.
\end{equation}
In this case, $E$~is the event that die~$A$ beats die~$B$, so
$\card{E} = 5$, \ $\card{\sspace} = 9$, and
\begin{equation*}
    \pr{E} = 5/9.
\end{equation*}

This is bad news for you.  Die~$A$ beats die~$B$ more than half the
time and, not surprisingly, you just lost~\$100.

Biker dude consoles you on your ``bad luck'' and, given that he's a
sensitive guy beneath all that leather, he offers to go double or
nothing.\footnote{\term{Double or nothing} is slang for doing another
  wager after you have lost the first.  If you lose again, you will
  owe biker dude \emph{double} what you owed him before.  If you win,
  you will now be even and you will owe him \emph{nothing}.}  Given
that your wallet only has \$25 in it, this sounds like a good plan.
Plus, you figure that choosing die~$A$ will give \emph{you} the
advantage.

So you choose~$A$ and biker dude chooses~$C$.  Can you guess who is
more likely to win?  (Hint: it is generally not a good idea to gamble
with someone you don't know in a bar, especially when you are gambling
with strange dice.)

\subsection{Die~$A$ versus Die~$C$}

We can construct the three diagram and outcome probabilities as
before.  The result is shown in Figure~\ref{fig:14A9} and there is bad
news again.  Die~$C$ will beat die~$A$ with probability~$5/9$, and you
lose once again.

\begin{figure}

\graphic{Fig_A9}

\caption{The tree diagram for one roll of die~$C$ versus die~$A$.
  Die~$C$ wins with probability~$5/9$.}

\label{fig:14A9}

\end{figure}

You now owe the biker dude \$200 and he asks for his money.  You reply
that you need to go to the bathroom.

Being a sensitive guy, biker dude nods understandingly and offers yet
another wager.  This time, he'll let you have die~$C$.  He'll even let
you raise the wager to~\$200 so you can get your money back.

This is too good a deal to pass up.  Die~$C$ is likely to beat die~$A$
and die~$A$ is likely to beat die~$B$, so the odds are surely in your
favor this time.  Biker dude must really be a nice guy.

So you pick~$C$ and biker dude picks~$B$.  Let's use the tree method
to figure out the probability that you win.

\subsection{Die~$B$ versus Die~$C$}

The tree diagram and outcome probabilities for $B$ versus~$C$ are
shown in Figure~\ref{fig:14A10}.  But surely there is a mistake!  The
data in Figure~\ref{fig:14A10} shows that \emph{die~$B$} wins with
probability~$5/9$.  How is it possible that
\begin{quote}

$B$ beats~$C$ with probability~$5/9$,

$C$ beats~$A$ with probability~$5/9$, and

$A$ beats~$B$ with probability~$5/9$?

\end{quote}

\begin{figure}

\graphic{Fig_A10}

\caption{The tree diagram for one roll of die~$B$ versus die~$C$.
  Die~$B$ wins with probability~$5/9$.}

\label{fig:14A10}

\end{figure}

The problem is not with the math, but with your intuition.  It
\emph{seems} that the ``likely-to-beat'' relation should be
transitive.  But it is not, and whatever die you pick, biker dude can
pick one of the others and be likely to win.  So picking first is a
big disadvantage and you now owe biker dude~\$400.

Just when you think matters can't get worse, biker dude offers you one
final wager for~\$1,000.  This time, you demand to choose second.
Biker dude agrees, but with the condition that instead of rolling each
die once, you each roll your die twice and your score is the sum of
your rolls.

Believing that you finally have a winning wager, you
agree.\footnote{Did we mention that playing strange gambling games
  with strangers in a bar is a bad idea?}  Biker dude chooses die~$B$
and, of course, you grab die~$A$.  That's because die~$A$ will beat
die~$B$ with probability~$5/9$ on one roll and so \emph{surely} two
rolls of die~$A$ are likely to beat two rolls of die~$B$, right?

Wrong!

\subsection{Rolling Twice}

If each player rolls twice, the tree diagram will have four levels and
$3^4 = 81$ outcomes.  This means that it will take a while to write
down the entire tree diagram.  We can, however, easily write down the
first two levels (as we have done in Figure~\ref{fig:14A11}(a)) and
then notice that the remaining two levels consist of nine identical
copies of the tree in Figure~\ref{fig:14A11}(b).

\begin{figure}

\graphic{Figure_A11}

\caption{Parts of the tree diagram for $B$ versus~$A$ where each die
  is rolled twice.  The first two levels are shown in~(a).  The last
  two levels consist of nine copies of the tree in~(b).}

\label{fig:14A11}

\end{figure}

The probability of each outcome is $(1/3)^4 = 1/81$ and so, once
again, we have a uniform probability space.  By
Equation~\ref{eqn:14F1}, this means that the probability that $A$~wins
is the number of outcomes where $A$ beats~$B$ divided by~81.

To compute the number of outcomes where $A$ beats~$B$, we observe that
the sum of the two rolls of die~$A$ is equally likely to be any
element of the following multiset:
\begin{equation*}
    \sspace_A = \set{ 4, 8, 8, 9, 9, 12, 13, 13, 14 }.
\end{equation*}
The sum of two rolls of die~$B$ is equally likely to be any element of
th following multiset:
\begin{equation*}
    \sspace_B = \set{ 2, 6, 6, 10, 10, 10, 14, 14, 18 }.
\end{equation*}
We can treat each outcome as a pair $(x, y) \in \sspace_A
\cross \sspace_B$, where $A$~wins iff $x > y$.  If $x = 4$, there is
only one~$y$ (namely $y = 2$) for which $x > y$.  If $x = 8$, there
are three values of~$y$ for which $x > y$.  Continuing the count in
this way, the number of pairs for which $x > y$ is
\begin{equation*}
    1 + 3 + 3 + 3 + 3 + 6 + 6 + 6 + 6 = 37.
\end{equation*}
A similar count shows that there are 42~pairs for which $x > y$, and
there are two pairs ($(14, 14)$, $(14, 14)$) which result in ties.
This means that $A$ \emph{loses} to~$B$ with probability $42/81 > 1/2$
and ties with probability~$2/81$.  Die~$A$ wins with probability
only~$37/81$.

How can it be that $A$~is more likely than~$B$ to win 1~roll, but $B$
is more likely to win 2~rolls?!?  Well, why not?  The only reason we'd
think otherwise is our (faulty) intuition.  In fact, the die strength
reverses no matter which two die we picked.  So for 1~roll,
\begin{equation*}
    A \succ B \succ C \succ A,
\end{equation*}
but for two rolls,
\begin{equation*}
    A \prec B \prec C \prec A,
\end{equation*}
where we have used the symbols $\succ$ and~$\prec$ to denote which die
is more likely to result in the larger value.  This is surprising even
to us, but at least we don't owe biker dude~\$1400.

\subsection{Even More Rolls}

Now that we know that strange things can happen with strange dice, it
is natural, at least for mathematicians, to ask how strange things can
get.  It turns out that things can get very strange.  In fact,
mathematicians\footnote{Reference Ron Graham paper.} recently made the
following discovery:

\begin{theorem}\label{thm:14F2}
For any $n \in \naturals$, there is a set of $n$~dice $D_1$, $D_2$,
\dots, $D_n$ such that for any $n$-node tournament
graph\footnote{Recall that a tournament graph is a directed graph for
  which there is precisely on directed edge between any two distinct
  nodes.  In other words, for every $u, v \in V(G)$, either $u$
  beats~$v$ or $v$ beats~$u$, but not both.}~$G$, there is a number of
rolls~$k$ such that if each die is rolled $k$~times, then for all $i
\ne j$, the sum of the $k$~rolls for~$D_i$ will exceed the sum
for~$D_j$ with probability greater than~$1/2$ iff $\diredge{D_i}{D_j}
\in E(G)$.
\end{theorem}

It will probably take a few attempts at reading Theorem~\ref{thm:14F2}
to understand what it is saying. The idea is that for some sets of
dice, by rolling them different numbers of times, the dice have
varying strengths relative to each other.  (This is what we observed
for the dice in Figure~\ref{fig:14A7}.)  Theorem~\ref{thm:14F2} says
that there is a set of (very) strange dice where \emph{every} possible
collection of relative strengths can be observed by varying the number
of rolls.  For example, the eight possible relative strengths for $n =
3$ dice are shown in Figure~\ref{fig:14A13}.  

\begin{figure}

\graphic{Fig_A13}

\caption{All possible relative strengths for three dice $D_1$, $D_2$,
  and~$D_3$.  The edge $\diredge{D_i}{D_j}$ denotes that the sum of
  rolls for~$D_i$ is likely to be greater than the sum of rolls
  for~$D_j$.}

\label{fig:14A13}

\end{figure}

Our analysis for the other dice in Figure~\ref{fig:14A7} showed that
for 1~roll, we have the relative strengths shown in
Figure~\ref{fig:14A13}(a) and for two rolls, we have the (reverse)
relative strengths shown in Figure~\ref{fig:14A13}(b). Can you figure
out what other relative strengths are possible for these dice by using
more rolls?  This might be worth doing if you are prone to gambling
with strangers in bars.

\subsection{Set Theory and Probability}

The study of probability is very closely tied to set theory.  That is
because any set can be a sample space.  Hence, sets and sample spaces
are the same thing.  This means that most of the rules and identities
that we have developed for sets extend very naturally to probability.
We'll cover several examples in this section, but first let's review
some definitions that should already be familiar.

\subsection{Probability Spaces}

\begin{definition}\label{LN12:sampsp}
  A countable\footnote{Yes, sample spaces can be infinite.  We'll see
    some examples shortly.  If you did not read
    Chapter~\ref{cardinality_chap}, don't worry---\emph{countable}
    means that you can list the elements of the sample space as $w_1$,
    $w_2$, $w_3$, \dots.} \term{sample space}, $\sspace$, is a
  nonempty countable set.  An element $w \in \sspace$ is called an
  \term{outcome}.  A subset of $\sspace$ is called an \term{event}.
\end{definition}

\begin{definition}\label{LN12:probsp}
 A \term{probability function} on a sample space, $\sspace$, is a total
 function $\operatorname{Pr}: \sspace\to \reals$ such that
\begin{itemize}
\item $\pr{w} \geq 0$ for all $w \in \sspace$, and
\item $\sum_{w \in \sspace} \pr{w} = 1$.
\end{itemize}
The sample space together with a probability function is called a
\term{probability space}.

For any event, $E \subseteq \sspace$, the \index{probability of an event}
\emph{probability of $E$} is defined to be the sum of the probabilities of
the outcomes in $E$:
\[
    \pr{E} \eqdef \sum_{w \in E} \pr{w}.
\]
\end{definition}

\subsection{Probability Rules from Set Theory}

An immediate consequence of the definition of event probability is
that for \emph{disjoint} events $E$ and~$F$,
\[
    \pr{E \union F} = \pr{E} + \pr{F}.
\]
This generalizes to a countable number of events, as follows.

\begin{rul*}[\idx{Sum Rule}]
  If $\set{E_0,E_1,\dots}$ is collection of pairwise disjoint
  events\footnote{A collection of events is \term{pairwise disjoint}
    if they do not share any outcomes.}, then
\[
    \Prob{\lgunion_{n\in\naturals}E_n} = \sum_{n\in\naturals} \pr{E_n}.
\]
\end{rul*}

The Sum Rule lets us analyze a complicated event by breaking it down
into simpler cases.  For example, if the probability that a randomly
chosen MIT student is native to the United States is 60\%, to Canada
is 5\%, and to Mexico is 5\%, then the probability that a random MIT
student is native to North America is 70\%.

Another consequence of the Sum Rule is that $\pr{A} + \pr{\bar{A}} = 1$,
which follows because $\pr{\sspace}=1$ and $\sspace$ is the union of the
disjoint sets $A$ and $\bar{A}$.  This equation often comes up in the form
\begin{rul*} [\idx{Complement Rule}]
\[
\pr{\bar{A}}  =  1 - \pr{A}.
\]
\end{rul*}
Sometimes the easiest way to compute the probability of an event is to compute
the probability of its complement and then apply this formula.

Some further basic facts about probability parallel facts about
cardinalities of finite sets.  In particular:
\begin{align}
\pr{B-A}        & =  \pr{B} - \pr{A \intersect B},\tag{Difference Rule}\\
\pr{A \union B} & =  \pr{A} + \pr{B} - \pr{A \intersect B},
                  \tag{Inclusion-Exclusion}\\
\pr{A \union B} & \le  \pr{A} + \pr{B}. \tag{Boole's Inequality}
\end{align}
The \idx{Difference Rule} follows from the Sum Rule because $B$ is the
union of the disjoint sets $B-A$ and $A \intersect B$.
\index{inclusion-exclusion for probabilities} Inclusion-Exclusion then
follows from the Sum and Difference Rules, because $A \union B$ is the
union of the disjoint sets $A$ and $B-A$.  \idx{Boole's inequality} is an
immediate consequence of Inclusion-Exclusion since probabilities are
nonnegative.

The two event Inclusion-Exclusion equation above generalizes to $n$ events
in the same way as the corresponding Inclusion-Exclusion rule for $n$
sets.  Boole's inequality also generalizes to
\begin{equation}
    \pr{E_1 \cup \cdots \cup E_n} \leq \pr{E_1} + \cdots + \pr{E_n}.\tag{Union Bound}
\end{equation}
This simple \idx{Union Bound} is useful in many calculations.  For
example, suppose that $E_i$ is the event that the $i$-th critical
component in a spacecraft fails.  Then $E_1 \cup \cdots \cup E_n$ is
the event that \emph{some} critical component fails.  The Union Bound
can give an adequate upper bound on this vital probability.

Similarly, the Difference Rule implies that
\begin{equation}\label{LN12:subsetbound}
\text{If } A \subseteq B, \text{ then } \pr{A} \le \pr{B}.\tag{Monotonicity}
\end{equation}

\subsection{Uniform Probability Spaces}

\begin{definition}\label{def:uniform_pspace}
A finite probability space~$\sspace$, $\Pr$ is said to be
\term{uniform} if $\pr{w}$ is the same for every outcome $w
\in \sspace$.
\end{definition}

As we saw in the strange dice problem, uniform sample spaces are
particularly easy to work with.  That's because for any event~$E
\subseteq \sspace$,
\begin{equation}\label{eqn:14G2}
    \pr{E} = \frac{\card{E}}{\card{\sspace}}.
\end{equation}
This means that once we know the cardinality of $E$ and~$\sspace$, we
can immediately obtain~$\pr{E}$.  That's great news because we
developed lots of tools for computing the cardinality of a set in
Part~\ref{part:counting}.

For example, suppose that you select five cards at random from a
standard deck of 52~cards.  What is the probability of having a full
house?  Normally, this question would take some effort to answer.  But
from the analysis in Section~\ref{sec:counting_full_houses}, we know
that
\begin{equation*}
    \card{\sspace} = \binom{13}{5}
\end{equation*}
and
\begin{equation*}
    \card{E} = 13 \cdot \binom{4}{3} \cdot 12 \cdot \binom{4}{2}
\end{equation*}
where $E$ is the event that we have a full house.  Since every
five-card hand is equally likely, we can apply Equation~\ref{eqn:14G2}
to find that
\begin{align*}
\pr{E}  &= \frac{13 \cdot 12 \cdot \binom{4}{3} \cdot \binom{4}{2}}
                {\binom{13}{5}} \\
        &= \frac{13 \cdot 12 \cdot 4 \cdot 6 \cdot 5 \cdot 4 \cdot 3 \cdot 2}
                {52 \cdot 51 \cdot 50 \cdot 49 \cdot 48} \\
        &= \frac{18}{12495} \\
        &\approx \frac{1}{694}.
\end{align*}

\subsection{Infinite Probability Spaces}

General probability theory deals with uncountable sets like~$\reals$,
but in computer science, it is sufficient to restrict our attention to
countable probability spaces.  It's also a lot easier---infinite
sample spaces are hard enough to work with without having to deal with
uncountable spaces.

Infinite probability spaces are fairly common.  For example, two
players take turns flipping a fair coin.  Whoever flips heads first is
declared the winner.  What is the probability that the first player
wins?  A tree diagram for this problem is shown in
Figure~\ref{fig:14A15}.

\begin{figure}

\graphic[height=2in]{infinite-tree1}

\caption{The tree diagram for the game where players take turns
  flipping a fair coin.  The first player to flip heads wins.}

\label{fig:14A15}

\end{figure}

The event that the first player wins contains an infinite number of
outcomes, but we can still sum their probabilities:
\begin{align*}
\pr{\text{first player wins}}
    & = \frac{1}{2} + \frac{1}{8} + \frac{1}{32} + \frac{1}{128} + \cdots \\
    & = \frac{1}{2} \sum_{n=0}^\infty \paren{\frac{1}{4}}^n \\
    & = \frac{1}{2}\paren{\frac{1}{1-1/4}} = \frac{2}{3}.
\end{align*}

Similarly, we can compute the probability that the second player wins:
\begin{align*}
\pr{\text{second player wins}}
    & = \frac{1}{4} + \frac{1}{16} + \frac{1}{64} + \frac{1}{256}
                      + \cdots \\
    & = \frac{1}{3}.
\end{align*}

In this case, the sample space is the infinite set
\[
    \sspace \eqdef \set{\, \tails^n\heads \suchthat n \in \naturals \,}
\]
where $\tails^n$ stands for a length $n$ string of $\tails$'s.
The probability function is
\[
\pr{\tails^n\heads} \eqdef \frac{1}{2^{n+1}}.
\]
To verify that this is a probability space, we just have to check that
all the probabilities are nonnegative and sum to~1.  Nonnegativity is
obvious and applying the formula for the sum of a geometric series, we
find that
\begin{align*}
\sum_{n \in \naturals} \pr{\tails^n\heads}
    &= \sum_{n \in \naturals} \frac{1}{2^{n+1}} \\
    &= 1.
\end{align*}

Notice that this model does not have an outcome corresponding to the
possibility that both players keep flipping tails forever---in the
diagram, flipping forever corresponds to following the infinite path
in the tree without ever reaching a leaf/outcome.  If leaving this
possibility out of the model bothers you, you're welcome to fix it by
adding another outcome, $w_{\text{forever}}$, to indicate that that's
what happened.  Of course since the probabilities of the other
outcomes already sum to 1, you have to define the probability of
$w_{\text{forever}}$ to be 0.  Outcomes with probability zero will
have no impact on our calculations, so there's no harm in adding it in
if it makes you happier.  On the other hand, there's also no harm in
simply leaving it out as we did, since it has no impact.

The mathematical machinery we've developed is adequate to model and
analyze many interesting probability problems with infinite sample
spaces.  However, some intricate infinite processes require
uncountable sample spaces along with more powerful (and more complex)
measure-theoretic notions of probability.  For example, if we generate
an infinite sequence of random bits $b_1, b_2, b_3, \ldots$, then what
is the probability that
\[
\frac{b_1}{2^1} + \frac{b_2}{2^2} + \frac{b_3}{2^3} + \cdots
\]
is a rational number?  Fortunately, we won't have any need to worry about
such things.


%% Set Theory and Probability Problems %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{problems}
\classproblems
\pinput{CP_system_component_failure}
\pinput{CP_proving_probability_rules}
\pinput{PS_conditional_space}
\end{problems}

\section{Problems}

\endinput
