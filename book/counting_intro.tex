\part{Counting}
\label{part:counting}

\clearpage

\section*{Introduction}

Counting seems easy enough: 1, 2, 3, 4, etc.  This direct approach
works well for counting simple things---like your toes---and may be
the only approach for extremely complicated things with no
identifiable structure.  However, subtler methods can help you count
many things in the vast middle ground, such as:
\begin{itemize}

\item The number of different ways to select a dozen doughnuts when
there are five varieties available.

\item The number of 16-bit numbers with exactly 4 ones.

\end{itemize}
Perhaps surprisingly, but certainly not coincidentally, the number in
each of these two situations is the same: 1820.

Counting is useful in computer science for several reasons:
\begin{itemize}

\item

Determining the time and storage required to solve a computational
problem---a central objective in computer science---often comes down
to solving a counting problem.

\item

Counting is the basis of probability theory, which plays a central
role in all sciences, including computer science.

\item

Two remarkable proof techniques, the ``\idx{pigeonhole principle}''
and ``\idx{combinatorial proof},'' rely on counting.  These lead to a
variety of interesting and useful insights.

\end{itemize}

In the next several chapters, we're going to present a lot of rules
for counting.  These rules are actually theorems, and we will prove
some of them, but our focus won't be on the proofs \emph{per se}---our
objective is to teach you simple counting as a practical skill, like
integration.

We begin our study of counting in Chapter~\ref{asymptotics_chap} with
a collection of rules and methods for finding closed-form expressions
for sums and products like $\sum_{i = 1}^n x^i$ and $n! =
\prod_{i=1}^n i$.  We also introduce asymptotic notation such as
$\sim$, $O$, and~$\Theta$ that is commonly used in computer science to
more simply express the dependence of a quantity such as the running
time of a program as a function of a parameter of the input.

\begin{editingnotes}
Suggested rewording (dmj):

\bigskip

We also introduce asymptotic notations such as $\sim$, $O$,
and~$\Theta$ that are commonly used in computer science to express the
how a quantity such as the running time of a program grows as a
function of a parameter representing the size of the input.

\bigskip

Or even ``grows with the size of the input''?

\end{editingnotes}

In Chapter~\ref{chap:recurrences}, we show how to solve a variety of
recurrences that arise in computational problems.  These methods are
especially useful when you need to design or analyze recursive
programs.

In Chapters \ref{counting_chap} and~\ref{generating_function_chap}, we
describe the most basic rules for determining the cardinality of a
set.  This material is simple yet powerful, and it provides a great
tool set for later use in your future career.\dmj{Redundant: Get rid
  of either ``later'' or ``future''.}

We conclude in Chapter~\ref{cardinality_chap} with a brief digression
into the final frontier of counting---infinity.  We'll define what it
means for a set to be countable and show you some examples of sets
that are really big---bigger even than the set of real numbers.

\endinput
