\part{Counting}
\label{part:counting}

\partintro

Counting seems easy enough: 1, 2, 3, 4, etc.  This direct approach
works well for counting simple things---like your toes---and may be
the only approach for extremely complicated things with no
identifiable structure.  However, subtler methods can help you count
many things in the vast middle ground, such as:
\begin{itemize}

\item The number of different ways to select a dozen doughnuts when
there are five varieties available.

\item The number of 16-bit numbers with exactly 4 ones.

\end{itemize}
Perhaps surprisingly, but certainly not coincidentally, the number in
each of these two situations is the same: 1820.

Counting is useful in computer science for several reasons:
\begin{itemize}

\item

Determining the time and storage required to solve a computational
problem ---a central objective in computer science ---often comes down
to solving a counting problem.

\item

Counting is the basis of probability theory, which plays a central
role in all sciences, including computer science.

\item

Two remarkable proof techniques, the ``\idx{pigeonhole principle}''
and ``\idx{combinatorial proof},'' rely on counting.
\iffalse
These lead to a variety of interesting and useful insights.
\fi

\end{itemize}

In the next several chapters, we're going to present a lot of rules
for counting.  These rules are actually theorems, and we will prove
some of them, but our focus won't be on the proofs \emph{per se} ---our
objective is to teach you simple counting as a practical skill, like
integration.

We begin our study of counting in Chapter~\ref{chap:asymptotics} with
a collection of rules and methods for finding closed-form expressions
for commonly-occurring sums and products such as $\sum_{i = 1}^n x^i$
and $n! = \prod_{i=1}^n i$.  We also introduce asymptotic notations
such as $\sim$, $O$, and~$\Theta$ that are commonly used in computer
science to express the how a quantity such as the running time of a
program grows with the size of the input.

\iffalse
In Chapter~\ref{chap:recurrences}, we show how to solve a variety of
recurrences that arise in computational problems.  These methods are
especially useful when you need to design or analyze recursive
programs.
\fi
In Chapter \ref{counting_chap}\iffalse
and~\ref{generating_function_chap}\fi
we describe the most basic rules for determining the cardinality of a
set.  This material is simple yet powerful, and it provides a great
tool set for use in your future career.

\iffalse
We conclude in Chapter~\ref{cardinality_chap} with a brief digression
into the final frontier of counting---infinity.  We'll define what it
means for a set to be countable and show you some examples of sets
that are really big---bigger even than the set of real numbers.
\fi

\endinput
