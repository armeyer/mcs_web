\hyperdef{propform}{english}{\chapter{Propositional Formulas}}\label{propform_chap}

It is amazing that people manage to cope with all the ambiguities in the
English language.  Here are some sentences that illustrate the issue:
%
\begin{enumerate}
\item ``You may have cake, or you may have ice cream.''
\item ``If pigs can fly, then you can understand the Chebyshev bound.''
\item ``If you can solve any problem we come up with, then you get an
  \emph{A} for the course.''
\item ``Every American has a dream.''
\end{enumerate}
%
What \emph{precisely} do these sentences mean?  Can you have both cake
and ice cream or must you choose just one dessert?  If the second
sentence is true, then is the Chebyshev bound incomprehensible?  If
you can solve some problems we come up with but not all, then do you
get an \emph{A} for the course?  And can you still get an \emph{A}
even if you can't solve any of the problems?  Does the last sentence
imply that all Americans have the same dream or might some of them
have different dreams?

Some uncertainty is tolerable in normal conversation.  But when we need to
formulate ideas precisely---as in mathematics and programming---the
ambiguities inherent in everyday language can be a real problem.  We can't
hope to make an exact argument if we're not sure exactly what the
statements mean.  So before we start into mathematics, we need to
investigate the problem of how to talk about mathematics.

To get around the ambiguity of English, mathematicians have devised a
special language for talking about logical relationships.  This language
mostly uses ordinary English words and phrases such as ``or'',
``implies'', and ``for all''.  But mathematicians endow these words with
definitions more precise than those found in an ordinary dictionary.
Without knowing these definitions, you might sometimes get the gist of
statements in this language, but you would regularly get misled about what
they really meant.

Surprisingly, in the midst of learning the language of logic, we'll
come across the most important open problem in computer science---a
problem whose solution could change the world.

\section{Propositions from Propositions}

In English, we can modify, combine, and relate propositions with words
such as ``not'', ``and'', ``or'', ``implies'', and ``if-then''.
For example, we can combine three propositions into one like this:
%
\begin{center}
\textbf{If} all humans are mortal \textbf{and} all Greeks are human,
\textbf{then} all Greeks are mortal.
\end{center}

For the next while, we won't be much concerned with the internals of
propositions---whether they involve mathematics or Greek mortality---but
rather with how propositions are combined and related.  So we'll
frequently use variables such as $P$ and $Q$ in place of specific
propositions such as ``All humans are mortal'' and ``$2 + 3 = 5$''.  The
understanding is that these variables, like propositions, can take on only
the values \true ~(true) and \false ~(false).  Such true/false variables are
sometimes called \term{Boolean variables} after their inventor, George
---you guessed it---Boole.

\subsection{``Not'', ``And'', and ``Or''}

We can precisely define these special words using \term{truth tables}.
For example, if $P$ denotes an arbitrary proposition, then the
truth of the proposition ``$\QNOT P$'' is defined by the following
truth table:
%
\[
\begin{array}{c|c}
P & \QNOT P \\ \hline
\true & \false \\
\false & \true \\
\end{array}
\]
%
The first row of the table indicates that when proposition $P$ is true,
the proposition ``$\QNOT P$'' is false.  The second line indicates that
when $P$ is false, ``$\QNOT P$'' is true.  This is probably what you would
expect.

In general, a truth table indicates the true/false value of a proposition
for each possible setting of the variables.  For example, the truth table
for the proposition ``$P \QAND Q$'' has four lines, since the two
variables can be set in four different ways:
%
\[
\begin{array}{cc|c}
P & Q & P \QAND Q \\ \hline
\true & \true & \true \\
\true & \false & \false \\
\false & \true & \false \\
\false & \false & \false
\end{array}
\]
%
According to this table, the proposition ``$P \QAND Q$'' is true only when
$P$ and $Q$ are both true.  This is probably the way you think about the
word ``and.''

There is a subtlety in the truth table for ``$P \QOR Q$'':
%
\[
\begin{array}{cc|c}
P & Q & P \QOR Q \\ \hline
\true & \true & \true \\
\true & \false & \true \\
\false & \true & \true \\
\false & \false & \false
\end{array}
\]
%
The third row of this table says that ``$P \QOR Q$'' is true when even if
\textit{both} $P$ and $Q$ are true.  This isn't always the intended
meaning of ``or'' in everyday speech, but this is the standard definition
in mathematical writing.  So if a mathematician says, ``You may have cake,
or you may have ice cream,'' he means that you \textit{could} have both.

If you want to exclude the possibility of having both having and eating, you should use
``exclusive-or'' ($\QXOR$):
%
\[\begin{array}{cc|c}
P & Q & P \QXOR Q \\ \hline
\true & \true & \false \\
\true & \false & \true \\
\false & \true & \true \\
\false & \false & \false
\end{array}
\]
%

\subsection{``Implies''}

The least intuitive connecting word is ``implies.''  Here is its truth
table, with the lines labeled so we can refer to them later.
%
\[
\begin{array}{cc|cr}
    P  &   Q    & \parbox[b]{13ex}{$P \QIMPLIES Q$} \\ \hline
\true  & \true  & \true & \text{(tt)}\\
\true  & \false & \false  & \text{(tf)}\\
\false & \true  & \true  & \text{(ft)}\\
\false & \false & \true  & \text{(ff)}
\end{array}
\]

Let's experiment with this definition.  For example, is the following
proposition true or false?
%
\begin{center}
``If Goldbach's Conjecture is true, then $x^2 \geq 0$ for every real
number $x$.''
\end{center}
%
Now, we told you before that no one knows whether Goldbach's Conjecture is
true or false.  But that doesn't prevent you from answering the question!
This proposition has the form $P \implies Q$ where the \term{hypothesis},
$P$, is ``Goldbach's Conjecture is true'' and the \term{conclusion}, $Q$,
is ``$x^2 \geq 0$ for every real number $x$''.  Since the conclusion is
definitely true, we're on either line~(tt) or line~(ft) of the truth
table.  Either way, the proposition as a whole is \textit{true}!

One of our original examples demonstrates an even stranger side of
implications.
%
\begin{center}
``If pigs fly, then you can understand the Chebyshev bound.''
\end{center}
%
Don't take this as an insult; we just need to figure out whether this
proposition is true or false.  Curiously, the answer has \textit{nothing}
to do with whether or not you can understand the Chebyshev bound.  Pigs do
not fly, so we're on either line (ft) or line (ff) of the truth table.  In
both cases, the proposition is \textit{true}!

In contrast, here's an example of a false implication:
%
\begin{center}
``If the moon shines white, then the moon is made of white cheddar.''
\end{center}
%
Yes, the moon shines white.  But, no, the moon is not made of white
cheddar cheese.  So we're on line (tf) of the truth table, and the
proposition is false.

The truth table for implications can be summarized in words as
follows:
%
\begin{center}
\textit{An implication is true exactly when the if-part is false or the
then-part is true.}
\end{center}
%
This sentence is worth remembering; a large fraction of all
mathematical statements are of the if-then form!

\subsection{``If and Only If''}

Mathematicians commonly join propositions in one additional way that
doesn't arise in ordinary speech.  The proposition ``$P$ if and only
if $Q$'' asserts that $P$ and $Q$ are logically equivalent; that is,
either both are true or both are false.
%
\[
\begin{array}{cc|c}
P & Q & P \QIFF Q \\ \hline
\true & \true & \true \\
\true & \false & \false \\
\false & \true & \false \\
\false & \false & \true
\end{array}
\]
%
The following if-and-only-if statement is true for every real number
$x$:
%
\begin{center}
$x^2 - 4 \geq 0 \qiff |x| \geq 2$
\end{center}
%
For some values of $x$, \textit{both} inequalities are true.  For
other values of $x$, \textit{neither} inequality is true .  In every
case, however, the proposition as a whole is true.

\begin{problems}
%\practiceproblems

\classproblems
\pinput{CP_differentiable_implies_continuous}
\pinput{CP_truth_table_for_distributive_law}

\homeworkproblems
\pinput{PS_printout_binary_strings}
\end{problems}

\section{Propositional Logic in Computer Programs}

Propositions and logical connectives arise all the time in computer
programs.  For example, consider the following snippet, which could be
either C, C++, or Java:
%
\begin{tabbing}
\hspace{1in} \= \quad\quad \= \quad\quad \= \quad\quad \= \kill
\> \texttt{if ( x > 0 || (x <= 0 \&\& y > 100) )} \\
\> \> \vdots\\
\> \textit{(further instructions)}
\end{tabbing}
%
The symbol \texttt{||} denotes ``or'', and the symbol \texttt{\&\&}
denotes ``and''.  The \textit{further instructions} are carried out
only if the proposition following the word \texttt{if} is true.  On
closer inspection, this big expression is built from two simpler
propositions.  Let $A$ be the proposition that \texttt{x > 0}, and let
$B$ be the proposition that \texttt{y > 100}.  Then we can rewrite the
condition this way:
%
\hyperdef{AAB}{snippet}{
\begin{equation}\label{ANAB}
A \text{ or } ((\text{not } A) \text{ and } B)
\end{equation}}
%
A truth table reveals that this complicated expression is logically
equivalent to 
\begin{equation}\label{AOB}
A \text{ or } B.
\end{equation}
%
\[
\begin{array}{cc|c|c}
A & B &
    A \text{ or } ((\text{not } A) \text{ and } B) &
    A \text{ or } B \\ \hline
\true & \true & \true & \true \\
\true & \false & \true & \true \\
\false & \true & \true & \true \\
\false & \false & \false & \false
\end{array}
\]
%
This means that we can simplify the code snippet without changing the
program's behavior:
%
\begin{tabbing}
\hspace{1in} \= \quad\quad \= \quad\quad \= \quad\quad \= \kill
\> \texttt{if ( x > 0 || y > 100 )} \\
\> \> \vdots\\
\> \textit{(further instructions)}
\end{tabbing}

The equivalence of~\eqref{ANAB} and~\eqref{AOB} can also be confirmed
reasoning by cases:
\begin{itemize}
\item[$A$ is \true.]  Then an expression of the form $(A \text{ or }
  \text{anything})$ will have truth value \true.  Since both expressions
  are of this form, both have the same truth value in this case, namely,
  \true.

\item[$A$ is \false.]  Then $(A \text{ or } P)$ will have the same truth
  value as $P$ for any proposition, $P$.  So~\eqref{AOB} has the same
  truth value as $B$.  Similarly,~\eqref{ANAB} has the same truth value as
  $((\text{not } \false) \text{ and } B)$, which also has the same value
  as $B$.  So in this case, both expressions will have the same truth
  value, namely, the value of $B$.
\end{itemize}

Rewriting a logical expression involving many variables in the
simplest form is both difficult and important.  Simplifying
expressions in software might slightly increase the speed of your
program.  But, more significantly, chip designers face essentially the
same challenge.  However, instead of minimizing \texttt{\&\&} and
\texttt{||} symbols in a program, their job is to minimize the number
of analogous physical devices on a chip.  The payoff is potentially
enormous: a chip with fewer devices is smaller, consumes less power,
has a lower defect rate, and is cheaper to manufacture.

\subsection{Cryptic Notation}

Programming languages use symbols like $\&\&$ and $!$ in place of
words like ``and'' and ``not''.  Mathematicians have devised their own
cryptic symbols to represent these words, which are summarized in the
table below.
%
\begin{center}
\begin{tabular}{ll}
\textbf{English} & \textbf{Cryptic Notation} \\[1ex]
not $P$ & $\neg P$ \quad (alternatively, $\bar{P}$) \\
$P$ and $Q$ & $P \wedge Q$ \\
$P$ or $Q$ & $P \vee Q$ \\
$P$ implies $Q$ & $P \implies Q$ \\
if $P$ then $Q$ & $P \implies Q$ \\
$P \qiff Q$ & $P \iff Q$
\end{tabular}
\end{center}
%
For example, using this notation, ``If $P$ and not $Q$, then $R$''
would be written:
%
\[
(P \wedge \bar{Q}) \implies R
\]

This symbolic language is helpful for writing complicated logical
expressions compactly.  But words such as ``$\QOR$'' and ``$\QIMPLIES$,''
generally serve just as well as the cryptic symbols $\vee$ and $\implies$,
and their meaning is easy to remember.  So we'll use the cryptic notation
sparingly, and we advise you to do the same.

\subsection{Logically Equivalent Implications}

Do these two sentences say the same thing?
%
\begin{center}
If I am hungry, then I am grumpy. \\
If I am not grumpy, then I am not hungry.
\end{center}
%
We can settle the issue by recasting both sentences in terms of
propositional logic.  Let $P$ be the proposition ``I am hungry'', and
let $Q$ be ``I am grumpy''.  The first sentence says ``$P$ implies
$Q$'' and the second says ``(not $Q$) implies (not $P$)''.  We can
compare these two statements in a truth table:
%
\[
\begin{array}{c|c|c|c}
P & Q &
    P \QIMPLIES Q &
    \bar{Q} \QIMPLIES \bar{P} \\ \hline
\true & \true & \true & \true \\
\true & \false & \false & \false \\
\false & \true & \true & \true \\
\false & \false & \true & \true
\end{array}
\]
%
Sure enough, the columns of truth values under these two statements are
the same, which precisely means they are equivalent.  In general,
``($\QNOT Q) \QIMPLIES (\QNOT P)$'' is called the \term{contrapositive} of
the implication ``$P \QIMPLIES Q$.''  And, as we've just shown, the two
are just different ways of saying the same thing.

In contrast, the \term{converse} of ``$P \QIMPLIES Q$'' is the statement
``$Q \QIMPLIES P$''.  In terms of our example, the converse is:
%
\begin{center}
If I am grumpy, then I am hungry.
\end{center}
%
This sounds like a rather different contention, and a truth table
confirms this suspicion:
%
\[
\begin{array}{c|c|c|c}
P & Q &
    P \QIMPLIES Q &
    Q \QIMPLIES P \\ \hline
\true & \true & \true & \true \\
\true & \false & \false & \true \\
\false & \true & \true & \false \\
\false & \false & \true & \true
\end{array}
\]
%
Thus, an implication \textit{is} logically equivalent to its
contrapositive but is \textit{not} equivalent to its converse.

One final relationship: an implication and its converse together are
equivalent to an iff statement, specifically, to these two statements
together.  For example,
%
\begin{center}
If I am grumpy, then I am hungry. \\
If I am hungry, then I am grumpy.
\end{center}
%
are equivalent to the single statement:
%
\begin{center}
I am grumpy iff I am hungry.
\end{center}
%
Once again, we can verify this with a truth table:
%
\[
\begin{array}{c|c|rclcrcl|rcl}
P & Q &
    (P &\QIMPLIES& Q) &\underline{\QAND}&  (Q &\QIMPLIES& P) & Q &\underline{\QIFF}& P \\
\hline
\true  &  \true  & &\true & &\true & &\true & & &\true & \\
\true  &  \false & &\false& &\false& &\true & & &\false& \\
\false &  \true  & &\true & &\false& &\false& & &\false& \\
\false &  \false & &\true & &\true & &\true & & &\true &
\end{array}
\]
The underlined operators have the same column of truth values, proving
that the corresponding formulas are equivalent.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage
\textbox{
\textboxtitle{SAT}

A proposition is \textbf{satisfiable} if some setting of the variables
makes the proposition true.  For example, $P \QAND \bar{Q}$ is
satisfiable because the expression is true when $P$ is true and $Q$ is
false.  On the other hand, $P \QAND \bar{P}$ is not satisfiable because
the expression as a whole is false for both settings of $P$.  But
determining whether or not a more complicated proposition is satisfiable
is not so easy.  How about this one?
%
\[
(P \QOR Q \QOR R) \QAND (\bar P \QOR \bar Q)
                  \QAND (\bar P \QOR \bar R)
                  \QAND (\bar R \QOR \bar Q)
\]

The general problem of deciding whether a proposition is satisfiable
is called \term{SAT}.  One approach to SAT is to construct a truth
table and check whether or not a $\true$ ever appears.  But this
approach is not very efficient; a proposition with $n$ variables has a
truth table with $2^n$ lines, so the effort required to decide about a
proposition grows \idx{exponentially} with the number of variables.
For a proposition with just 30 variables, that's already over a
billion!

Is there a more \textit{efficient} solution to SAT?  In particular, is
there some, presumably very ingenious, procedure that determines in a
number of steps that grows \emph{polynomially}---like $n^2$ of
$n^{14}$---instead of exponentially, whether any given proposition is
satifiable or not?  No one knows.  And an awful lot hangs on the
answer.  An efficient solution to SAT would immediately imply
efficient solutions to many, many other important problems involving
packing, scheduling, routing, and circuit verification, among other
things.  This would be wonderful, but there would also be worldwide
chaos.  Decrypting coded messages would also become an easy task (for
most codes).  Online financial transactions would be insecure and
secret communications could be read by everyone.

Recently there has been exciting progress on \term{sat-solvers} for
practical applications like digital circuit verification.  These
programs find satisfying assignments with amazing efficiency even for
formulas with millions of variables.  Unfortunately, it's hard to
predict which kind of formulas are amenable to sat-solver methods, and
for formulas that are NOT satisfiable, sat-solvers generally take
exponential time to verify that.

So no one has a good idea how to solve SAT more efficiently or else to
prove that no efficient solution exists---researchers are completely
stuck.  This is the outstanding unanswered question in theoretical
computer science.}

\begin{problems}
%\practiceproblems
\classproblems
\pinput{CP_file_system_functioning_normally}
\pinput{CP_binary_adder_logic}
\pinput{CP_valid_vs_satisfiable}

\homeworkproblems

\pinput{PS_faster_adder_logic}

\end{problems}

\endinput
